{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR8E6URZK1X3"
      },
      "source": [
        "# 기본환경 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi2W6IsEFm8D",
        "outputId": "ce373008-0ebb-47f0-e341-ff014b350b7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os, re, unicodedata, pathlib, random\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm\n",
        "import sentencepiece as spm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# 경로/디바이스\n",
        "DATA_DIR = pathlib.Path(\"data/ko_wikisource_clean\"); DATA_DIR.mkdir(exist_ok=True)\n",
        "RAW_TXT  = DATA_DIR/\"raw.txt\"\n",
        "NORM_TXT = DATA_DIR/\"norm_nfc.txt\"\n",
        "SPM_PREFIX = str(DATA_DIR/\"spm_ko\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-zyVfXSBFm8D"
      },
      "outputs": [],
      "source": [
        "# 필요에 따라 더 추가하세요\n",
        "URLS = [\n",
        "    \"https://ko.wikisource.org/wiki/B%EB%85%80%EC%9D%98_%EC%86%8C%EB%AC%98\",  # B녀의 소묘\n",
        "    \"https://ko.wikisource.org/wiki/%EB%8C%80%EB%8F%99%EA%B0%95%EC%9D%80_%EC%86%8D%EC%82%AD%EC%9D%B8%EB%8B%A4\",  # 대동강은 속삭인다\n",
        "    \"https://ko.wikisource.org/wiki/%EB%8C%80%ED%83%95%EC%A7%80_%EC%95%84%EC%A3%BC%EB%A8%B8%EB%8B%88\",  # 대탕지 아주머니\n",
        "    \"https://ko.wikisource.org/wiki/%EB%8F%84%EC%8B%9C%EC%99%80_%EC%9C%A0%EB%A0%B9\",  # 도시와 유령\n",
        "    \"https://ko.wikisource.org/wiki/%EB%8F%84%EC%A0%95\", # 도정\n",
        "    \"https://ko.wikisource.org/wiki/%EB%A7%8C%EB%AC%B4%EB%B0%A9\", # 만무방\n",
        "    \"https://ko.wikisource.org/wiki/%EB%AC%B4%EB%AA%85%EC%B4%88\", # 무명초\n",
        "    \"https://ko.wikisource.org/wiki/%EB%AC%BC\", # 물\n",
        "    \"https://ko.wikisource.org/wiki/%EB%AC%BC%EB%A0%88%EB%B0%A9%EC%95%84\", # 물레방아\n",
        "    \"https://ko.wikisource.org/wiki/%EB%B0%98%EC%97%AD%EC%9E%90\", # 반역자\n",
        "    \"https://ko.wikisource.org/wiki/%EC%9A%A9%EA%B3%BC_%EC%9A%A9%EC%9D%98_%EB%8C%80%EA%B2%A9%EC%A0%84\", # 용과 용의 대격전\n",
        "    \"https://ko.wikisource.org/wiki/%EC%9A%B0%EC%97%B0%EC%9D%98_%EA%B8%B0%EC%A0%81\", # 우연의 기적\n",
        "    \"https://ko.wikisource.org/wiki/%EC%9A%B4%EC%88%98_%EC%A2%8B%EC%9D%80_%EB%82%A0\", # 운수 좋은 날\n",
        "    \"https://ko.wikisource.org/wiki/%EC%9B%90%EC%88%98%EB%A1%9C_%EC%9D%80%EC%9D%B8\", # 원수로 은인\n",
        "    \"https://ko.wikisource.org/wiki/%EC%9C%A0%EB%AC%B4\", # 유무\n",
        "    \"https://ko.wikisource.org/wiki/%EC%9C%A4%EA%B4%91%ED%98%B8\", # 윤광호\n",
        "    \"https://ko.wikisource.org/wiki/%EC%9D%B4_%EC%9E%94%EC%9D%84\", # 이 잔을\n",
        "    \"https://ko.wikisource.org/wiki/%EC%9D%B4%EC%8B%9D%EA%B3%BC_%EB%8F%84%EC%8A%B9\", # 이식과 도승\n",
        "    \"https://ko.wikisource.org/wiki/%EC%9D%BC%ED%91%9C%EC%9D%98_%EA%B3%B5%EB%8A%A5\", # 일표의 공능\n",
        "    \"https://ko.wikisource.org/wiki/%EC%9E%A1%EC%B4%88\", # 잡초\n",
        "    \"https://ko.wikisource.org/wiki/%EC%9E%A5%EB%AF%B8_%EB%B3%91%EB%93%A4%EB%8B%A4\", # 장미 병들다\n",
        "    \"https://ko.wikisource.org/wiki/%EC%A0%81%EA%B4%B4%EC%9C%A0%EC%9D%98\", # 적괴유의\n",
        "    \"https://ko.wikisource.org/wiki/%EC%A0%81%EB%A7%89%ED%95%9C_%EC%A0%80%EB%85%81\", # 적막한 저녁\n",
        "    \"https://ko.wikisource.org/wiki/%EC%A0%81%EB%B9%88\", # 적빈\n",
        "    \"https://ko.wikisource.org/wiki/%EC%A0%84%EC%A0%9C%EC%9E%90\", # 전제자\n",
        "    \"https://ko.wikisource.org/wiki/%EC%A0%95%EC%97%B4%EC%9D%98_%EB%82%99%EB%9E%91%EA%B3%B5%EC%A3%BC\", # 정열의 낙랑공주\n",
        "    \"https://ko.wikisource.org/wiki/%EC%A0%95%EC%A1%B0_(%EA%B9%80%EC%9C%A0%EC%A0%95)\", # 정조 (김유정)\n",
        "    \"https://ko.wikisource.org/wiki/%EC%A0%95%ED%9D%AC\", # 정희\n",
        "    \"https://ko.wikisource.org/wiki/%EC%A2%85%EC%83%9D%EA%B8%B0\", # 종생기\n",
        "    \"https://ko.wikisource.org/wiki/%EC%A3%84%EC%99%80_%EB%B2%8C_(%EA%B9%80%EB%8F%99%EC%9D%B8)\", # 죄와 벌 (김동인)\n",
        "    \"https://ko.wikisource.org/wiki/%EC%A7%80%EB%8F%84%EC%9D%98_%EC%95%94%EC%8B%A4\", # 지도의 암실\n",
        "    \"https://ko.wikisource.org/wiki/%EC%A7%80%ED%95%98%EC%B4%8C\", # 지하촌\n",
        "    \"https://ko.wikisource.org/wiki/%EC%AB%93%EA%B8%B0%EC%96%B4_%EA%B0%80%EB%8A%94_%EC%9D%B4%EB%93%A4\", # 쫓기어 가는 이들\n",
        "    \"https://ko.wikisource.org/wiki/%EC%B2%AD%EC%B6%98\", # 청춘\n",
        "    \"https://ko.wikisource.org/wiki/%EC%B4%88%EC%B7%8C%EC%97%B0%ED%99%94%ED%8E%B8\", # 초췌연화편\n",
        "    \"https://ko.wikisource.org/wiki/%EC%B4%9D%EA%B0%81%EA%B3%BC_%EB%A7%B9%EA%BD%81%EC%9D%B4\", # 총각과 맹꽁이\n",
        "    \"https://ko.wikisource.org/wiki/%EC%B9%98%EC%88%99\", # 치숙\n",
        "    \"https://ko.wikisource.org/wiki/%ED%83%9C%ED%98%95\", # 태형\n",
        "    \"https://ko.wikisource.org/wiki/%ED%88%AC%ED%99%98%EA%B8%88%EC%9D%80\", # 투환금은\n",
        "    \"https://ko.wikisource.org/wiki/%ED%95%B4%EB%8F%8B%EC%9D%B4\", # 해돋이\n",
        "    \"https://ko.wikisource.org/wiki/%ED%99%8D%EC%9C%A4%EC%84%B1%EA%B3%BC_%EC%A0%88%EB%B6%80\", # 홍윤성과 절부\n",
        "    \"https://ko.wikisource.org/wiki/%EC%82%AC%EA%B0%81%EC%A0%84%EA%B8%B0\", # 사각전기\n",
        "    \"https://ko.wikisource.org/wiki/%EC%82%AC%EC%83%9D%EC%95%84\", # 사생아\n",
        "    \"https://ko.wikisource.org/wiki/%EC%82%AC%EC%9C%84\", # 사위\n",
        "    \"https://ko.wikisource.org/wiki/%EC%82%B0%EA%B3%A8\", # 산골\n",
        "    \"https://ko.wikisource.org/wiki/%EC%82%B0%EA%B3%A8_%EB%82%98%EA%B7%B8%EB%84%A4\", # 산골 나그네\n",
        "    \"https://ko.wikisource.org/wiki/%EC%82%B0%EB%82%A8\", # 산남\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sMsrIJUFm8E"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g1MVbWq0Fm8E"
      },
      "outputs": [],
      "source": [
        "def fetch_wikisource_text(url):\n",
        "    headers = {\n",
        "        \"User-Agent\": (\n",
        "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "            \"Chrome/120.0.0.0 Safari/537.36\"\n",
        "        )\n",
        "    }\n",
        "    r = requests.get(url, headers=headers, stream=True, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    soup = BeautifulSoup(r.text, \"lxml\")\n",
        "\n",
        "    # 본문 컨테이너\n",
        "    content = soup.select_one(\"div.mw-parser-output\")\n",
        "    if content is None:\n",
        "        return \"\"\n",
        "\n",
        "    # 표/주석/각주 등 제거\n",
        "    for selector in [\"table\", \"div.reflist\", \"ol.references\", \"sup.reference\"]:\n",
        "        for tag in content.select(selector):\n",
        "            tag.decompose()\n",
        "\n",
        "    # 문단과 리스트 텍스트만 추출\n",
        "    texts = []\n",
        "    for tag in content.find_all([\"p\",\"li\",\"dd\",\"dt\",\"blockquote\"]):\n",
        "        txt = tag.get_text(\" \", strip=True)\n",
        "        if txt:\n",
        "            texts.append(txt)\n",
        "\n",
        "    text = \"\\n\".join(texts)\n",
        "\n",
        "    # 위키마크업 잔여 정리\n",
        "    text = re.sub(r\"\\[편집\\]|\\[.*?편집\\]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text.strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-06T11:11:51.442548Z",
          "iopub.status.busy": "2025-09-06T11:11:51.442237Z",
          "iopub.status.idle": "2025-09-06T11:11:51.445782Z",
          "shell.execute_reply": "2025-09-06T11:11:51.445028Z",
          "shell.execute_reply.started": "2025-09-06T11:11:51.442523Z"
        },
        "id": "xD8g6tJ0Fm8E"
      },
      "source": [
        "# 수집 → NFC 정규화 → 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDN72PHrFm8E",
        "outputId": "3f4ca663-922c-44c1-fe32-802b087d76d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1/47 [00:01<01:03,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 15,052 chars from https://ko.wikisource.org/wiki/B%EB%85%80%EC%9D%98_%EC%86%8C%EB%AC%98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/47 [00:02<00:45,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 13,571 chars from https://ko.wikisource.org/wiki/%EB%8C%80%EB%8F%99%EA%B0%95%EC%9D%80_%EC%86%8D%EC%82%AD%EC%9D%B8%EB%8B%A4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 3/47 [00:02<00:31,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 15,664 chars from https://ko.wikisource.org/wiki/%EB%8C%80%ED%83%95%EC%A7%80_%EC%95%84%EC%A3%BC%EB%A8%B8%EB%8B%88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 4/47 [00:03<00:28,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 12,302 chars from https://ko.wikisource.org/wiki/%EB%8F%84%EC%8B%9C%EC%99%80_%EC%9C%A0%EB%A0%B9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 5/47 [00:04<00:31,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 18,738 chars from https://ko.wikisource.org/wiki/%EB%8F%84%EC%A0%95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 6/47 [00:04<00:34,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 23,154 chars from https://ko.wikisource.org/wiki/%EB%A7%8C%EB%AC%B4%EB%B0%A9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 7/47 [00:05<00:32,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 22,081 chars from https://ko.wikisource.org/wiki/%EB%AC%B4%EB%AA%85%EC%B4%88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 8/47 [00:06<00:28,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 9,720 chars from https://ko.wikisource.org/wiki/%EB%AC%BC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 9/47 [00:07<00:28,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 12,688 chars from https://ko.wikisource.org/wiki/%EB%AC%BC%EB%A0%88%EB%B0%A9%EC%95%84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 10/47 [00:07<00:27,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 9,262 chars from https://ko.wikisource.org/wiki/%EB%B0%98%EC%97%AD%EC%9E%90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 11/47 [00:08<00:29,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 17,885 chars from https://ko.wikisource.org/wiki/%EC%9A%A9%EA%B3%BC_%EC%9A%A9%EC%9D%98_%EB%8C%80%EA%B2%A9%EC%A0%84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 12/47 [00:09<00:25,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 10,753 chars from https://ko.wikisource.org/wiki/%EC%9A%B0%EC%97%B0%EC%9D%98_%EA%B8%B0%EC%A0%81\n",
            "Fetched 10,582 chars from https://ko.wikisource.org/wiki/%EC%9A%B4%EC%88%98_%EC%A2%8B%EC%9D%80_%EB%82%A0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 14/47 [00:10<00:19,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 13,484 chars from https://ko.wikisource.org/wiki/%EC%9B%90%EC%88%98%EB%A1%9C_%EC%9D%80%EC%9D%B8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 15/47 [00:10<00:18,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 7,729 chars from https://ko.wikisource.org/wiki/%EC%9C%A0%EB%AC%B4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 16/47 [00:11<00:18,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 14,997 chars from https://ko.wikisource.org/wiki/%EC%9C%A4%EA%B4%91%ED%98%B8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 17/47 [00:11<00:17,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 8,790 chars from https://ko.wikisource.org/wiki/%EC%9D%B4_%EC%9E%94%EC%9D%84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 18/47 [00:12<00:18,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 12,770 chars from https://ko.wikisource.org/wiki/%EC%9D%B4%EC%8B%9D%EA%B3%BC_%EB%8F%84%EC%8A%B9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 19/47 [00:13<00:15,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 10,926 chars from https://ko.wikisource.org/wiki/%EC%9D%BC%ED%91%9C%EC%9D%98_%EA%B3%B5%EB%8A%A5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 20/47 [00:13<00:15,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 22,143 chars from https://ko.wikisource.org/wiki/%EC%9E%A1%EC%B4%88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 21/47 [00:14<00:12,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 18,094 chars from https://ko.wikisource.org/wiki/%EC%9E%A5%EB%AF%B8_%EB%B3%91%EB%93%A4%EB%8B%A4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 22/47 [00:14<00:14,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 11,638 chars from https://ko.wikisource.org/wiki/%EC%A0%81%EA%B4%B4%EC%9C%A0%EC%9D%98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 23/47 [00:15<00:14,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 13,758 chars from https://ko.wikisource.org/wiki/%EC%A0%81%EB%A7%89%ED%95%9C_%EC%A0%80%EB%85%81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 24/47 [00:16<00:14,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 11,318 chars from https://ko.wikisource.org/wiki/%EC%A0%81%EB%B9%88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 25/47 [00:16<00:12,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 13,000 chars from https://ko.wikisource.org/wiki/%EC%A0%84%EC%A0%9C%EC%9E%90\n",
            "Fetched 13,674 chars from https://ko.wikisource.org/wiki/%EC%A0%95%EC%97%B4%EC%9D%98_%EB%82%99%EB%9E%91%EA%B3%B5%EC%A3%BC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 27/47 [00:16<00:07,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 8,839 chars from https://ko.wikisource.org/wiki/%EC%A0%95%EC%A1%B0_(%EA%B9%80%EC%9C%A0%EC%A0%95)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 28/47 [00:17<00:07,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 17,159 chars from https://ko.wikisource.org/wiki/%EC%A0%95%ED%9D%AC\n",
            "Fetched 19,397 chars from https://ko.wikisource.org/wiki/%EC%A2%85%EC%83%9D%EA%B8%B0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 30/47 [00:17<00:06,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 10,158 chars from https://ko.wikisource.org/wiki/%EC%A3%84%EC%99%80_%EB%B2%8C_(%EA%B9%80%EB%8F%99%EC%9D%B8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 31/47 [00:18<00:05,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 10,279 chars from https://ko.wikisource.org/wiki/%EC%A7%80%EB%8F%84%EC%9D%98_%EC%95%94%EC%8B%A4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 32/47 [00:19<00:07,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 33,623 chars from https://ko.wikisource.org/wiki/%EC%A7%80%ED%95%98%EC%B4%8C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 33/47 [00:19<00:07,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 17,724 chars from https://ko.wikisource.org/wiki/%EC%AB%93%EA%B8%B0%EC%96%B4_%EA%B0%80%EB%8A%94_%EC%9D%B4%EB%93%A4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 34/47 [00:21<00:10,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 79,953 chars from https://ko.wikisource.org/wiki/%EC%B2%AD%EC%B6%98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 35/47 [00:21<00:08,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 11,715 chars from https://ko.wikisource.org/wiki/%EC%B4%88%EC%B7%8C%EC%97%B0%ED%99%94%ED%8E%B8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 36/47 [00:22<00:07,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 7,186 chars from https://ko.wikisource.org/wiki/%EC%B4%9D%EA%B0%81%EA%B3%BC_%EB%A7%B9%EA%BD%81%EC%9D%B4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▊  | 37/47 [00:22<00:06,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 14,233 chars from https://ko.wikisource.org/wiki/%EC%B9%98%EC%88%99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 38/47 [00:23<00:05,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 14,163 chars from https://ko.wikisource.org/wiki/%ED%83%9C%ED%98%95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 39/47 [00:24<00:05,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 11,306 chars from https://ko.wikisource.org/wiki/%ED%88%AC%ED%99%98%EA%B8%88%EC%9D%80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 40/47 [00:25<00:05,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 34,010 chars from https://ko.wikisource.org/wiki/%ED%95%B4%EB%8F%8B%EC%9D%B4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 41/47 [00:25<00:04,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 16,139 chars from https://ko.wikisource.org/wiki/%ED%99%8D%EC%9C%A4%EC%84%B1%EA%B3%BC_%EC%A0%88%EB%B6%80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 42/47 [00:26<00:03,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 9,174 chars from https://ko.wikisource.org/wiki/%EC%82%AC%EA%B0%81%EC%A0%84%EA%B8%B0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 43/47 [00:27<00:02,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 13,827 chars from https://ko.wikisource.org/wiki/%EC%82%AC%EC%83%9D%EC%95%84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 44/47 [00:27<00:01,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 14,668 chars from https://ko.wikisource.org/wiki/%EC%82%AC%EC%9C%84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 45/47 [00:28<00:01,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 12,724 chars from https://ko.wikisource.org/wiki/%EC%82%B0%EA%B3%A8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 46/47 [00:28<00:00,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 10,174 chars from https://ko.wikisource.org/wiki/%EC%82%B0%EA%B3%A8_%EB%82%98%EA%B7%B8%EB%84%A4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 47/47 [00:29<00:00,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 12,069 chars from https://ko.wikisource.org/wiki/%EC%82%B0%EB%82%A8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(746214, 746168, 'data/ko_wikisource_clean/norm_nfc.txt')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "all_texts = []\n",
        "for u in tqdm(URLS):\n",
        "    try:\n",
        "        t = fetch_wikisource_text(u)\n",
        "        print(f\"Fetched {len(t):,} chars from {u}\")\n",
        "        if len(t) > 1000:\n",
        "            all_texts.append(f\"\\n\\n### SOURCE: {u}\\n{t}\")\n",
        "    except Exception as e:\n",
        "        print(\"Failed:\", u, e)\n",
        "\n",
        "raw_text = \"\\n\".join(all_texts)\n",
        "RAW_TXT.write_text(raw_text, encoding=\"utf-8\")\n",
        "\n",
        "# 한글 자모 분리 방지: NFC 정규화. ᄀ(U+1100)+ᅡ(U+1161)(분리 자모) ↔ 가(U+AC00)(완성형)\n",
        "norm_text = unicodedata.normalize(\"NFC\", raw_text) # Normalization Form Composition, Normalization Form Decomposition\n",
        "\n",
        "# 공백 정리\n",
        "norm_text = re.sub(r\"\\r\\n?\", \"\\n\", norm_text)\n",
        "norm_text = re.sub(r\"[ \\t]+\", \" \", norm_text)\n",
        "norm_text = re.sub(r\"\\n{3,}\", \"\\n\\n\", norm_text)\n",
        "\n",
        "NORM_TXT.write_text(norm_text, encoding=\"utf-8\")\n",
        "(len(raw_text), len(norm_text), str(NORM_TXT))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUX9C5z2Fm8E"
      },
      "source": [
        "# 토크나이저 생성"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm"
      ],
      "metadata": {
        "id": "hzHW2Gh6HRTm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) 한글 음절만 required에 유지\n",
        "ko_chars = \"\".join(chr(c) for c in range(0xAC00, 0xD7A4))  # 가–힣"
      ],
      "metadata": {
        "id": "sIm9cgb4HRRW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) 문장부호는 user_defined_symbols로만 (원래 리스트 그대로 사용 가능)\n",
        "user_syms = [\"《\",\"》\",\"〈\",\"〉\",\"—\",\"…\",\"“\",\"”\",\"‘\",\"’\",\"·\",\"『\",\"』\",\"「\",\"」\",\"‧\"]"
      ],
      "metadata": {
        "id": "0AGstMSkHROu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) 혹시라도 겹치는 게 있으면 required에서 제거 (방어적)\n",
        "required = \"\".join(ch for ch in ko_chars if ch not in set(user_syms))"
      ],
      "metadata": {
        "id": "Fnoo3w5MHRD7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = dict(\n",
        "    input=str(NORM_TXT),                 # 학습에 사용할 입력 코퍼스 경로(또는 쉼표로 여러 파일). str(...)로 문자열 보장\n",
        "    model_prefix=SPM_PREFIX,             # 출력 모델/사전 파일 접두사(sp.model / sp.vocab 파일명 앞부분)\n",
        "    model_type=\"unigram\",                # 토크나이저 모델 유형: unigram(기본), bpe, char, word 등 중 선택\n",
        "\n",
        "    vocab_size=16000,                    # 최종 어휘 수(특수토큰 포함). 너무 작으면 OOV↑, 너무 크면 메모리/속도↓\n",
        "    character_coverage=0.9999,           # 문자 커버리지 목표. 저빈도 문자를 잘라낼 기준(라틴 기반 언어는 1.0 근처 추천)\n",
        "\n",
        "    # ★ 라운드트립(원문 복원) 보장용 설정\n",
        "    normalization_rule_name=\"identity\",  # 정규화 규칙 비활성화(원문을 그대로 유지). NFKC 등 사용 안 함\n",
        "    byte_fallback=True,                  # 어휘에 없는 임의의 문자도 바이트 시퀀스로 분해해 인코딩/디코딩 가능하게 함\n",
        "    hard_vocab_limit=False,              # True면 vocab_size를 절대 넘지 않음. False면 필수 심볼 때문에 소폭 초과 허용\n",
        "\n",
        "    add_dummy_prefix=True,               # 문장 앞에 공백 토큰(▁)을 강제로 추가해 단어 경계 학습을 안정화\n",
        "                                         # 디코딩 시에도 공백 복원에 유리(문두 토큰화 일관성↑)\n",
        "\n",
        "    unk_id=0,                            # <unk> 토큰의 ID(미등록 토큰 대체). -1이면 비활성화\n",
        "    unk_surface=\"<unk>\",                 # <unk>가 출력될 때 보이는 표면 문자열. unknown (토크나이저가 어휘(vocab)로 표현할 수 없는 문자)\n",
        "    bos_id=1, bos_piece=\"<s>\",           # 문장 시작 토큰(BOS) 비활성화(-1). 사용하려면 0 이상의 ID로 지정\n",
        "    eos_id=2, eos_piece=\"</s>\",          # 문장 종료 토큰(EOS) 비활성화(-1). 사용하려면 0 이상의 ID로 지정\n",
        "    pad_id=-3, pad_piece=\"<pad>\",         # PAD 토큰 비활성화(-1). 필요 시 ID 지정하여 패딩 토큰 사용\n",
        "\n",
        "    user_defined_symbols=user_syms,      # 그대로 하나의 토큰으로 취급할 사용자 정의 “문자열” 목록(예: <url>, <email>, 특수기호 등)\n",
        "\n",
        "    max_sentence_length=100000,          # 단일 문장(줄)에서 학습에 사용할 최대 길이(문자 수). 너무 길면 잘라서 사용\n",
        "    input_sentence_size=4_000_000,       # 학습에 샘플링해 사용할 문장 개수(코퍼스가 매우 클 때 속도/메모리 절충)\n",
        "    shuffle_input_sentence=True,         # 샘플링 전 문장을 섞어 편향 감소(코퍼스 순서성 영향 완화)\n",
        ")\n",
        "\n",
        "\n",
        "try:\n",
        "    spm.SentencePieceTrainer.train(required_chars=required, **kwargs)\n",
        "except TypeError:\n",
        "    # 구버전 sentencepiece면 required_chars 미지원 → 그냥 진행\n",
        "    print(\"[WARN] required_chars 미지원 → 커버리지/어휘 설정으로 진행합니다.\")\n",
        "    spm.SentencePieceTrainer.train(**kwargs)"
      ],
      "metadata": {
        "id": "AV-7zOIqHQtD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(SPM_PREFIX + \".model\")\n",
        "print(\"vocab_size:\", sp.get_piece_size(), \"unk_id:\", sp.unk_id(), \"unk_piece:\", sp.id_to_piece(sp.unk_id()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmoQMJsmIg7x",
        "outputId": "aba92afd-4233-464e-c0e0-413e76accdd1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab_size: 16000 unk_id: 0 unk_piece: <unk>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4qy6Qs0Fm8F",
        "outputId": "34846727-328f-404a-e1ee-4588a24f9c57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roundtrip: True\n"
          ]
        }
      ],
      "source": [
        "# 라운드트립 체크\n",
        "def roundtrip_ok(txt: str) -> bool:\n",
        "    pieces = sp.encode(txt, out_type=str)\n",
        "    back = sp.decode(pieces)\n",
        "    return txt == back\n",
        "\n",
        "test_str = \"《테스트》 “따옴표”… — 『괄호』 「문장」 ‧ 끝!\"\n",
        "print(\"roundtrip:\", roundtrip_ok(test_str))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mnunsamFm8F"
      },
      "source": [
        "# 토큰화 무손실 확인 (decode == 원문)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWCKcutlFm8F",
        "outputId": "2a29f8b2-4c31-45e3-fd1d-e6d0a38ab3d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pieces: ['▁성', '춘', '향', '은', '▁이', '▁', '도', '령', '을', '▁깊이', '▁사', '모', '하였', '더라', '.']\n",
            "ids   : [969, 3852, 3262, 284, 295, 275, 285, 2034, 277, 1891, 375, 1322, 2090, 2058, 276]\n",
            "back_p: 성춘향은 이 도령을 깊이 사모하였더라.\n",
            "back_i: 성춘향은 이 도령을 깊이 사모하였더라.\n"
          ]
        }
      ],
      "source": [
        "import unicodedata\n",
        "\n",
        "def debug_roundtrip(s):\n",
        "    s_nfc = unicodedata.normalize(\"NFC\", s)\n",
        "    pieces = sp.encode(s_nfc, out_type=str)\n",
        "    ids    = sp.encode(s_nfc, out_type=int)\n",
        "    back_p = sp.decode(pieces)\n",
        "    back_i = sp.decode(ids)\n",
        "    print(\"pieces:\", pieces)\n",
        "    print(\"ids   :\", ids)\n",
        "    print(\"back_p:\", back_p)\n",
        "    print(\"back_i:\", back_i)\n",
        "    # UNK 존재 여부\n",
        "    unk_positions = [i for i,t in enumerate(ids) if t == sp.unk_id()]\n",
        "    if unk_positions:\n",
        "        print(\"⚠️  UNK at positions:\", unk_positions)\n",
        "    assert back_i == s_nfc, \"decode(encode(x))가 원문과 다릅니다!\"\n",
        "\n",
        "test_line = \"성춘향은 이 도령을 깊이 사모하였더라.\"\n",
        "debug_roundtrip(test_line)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsCJqxnRFm8F"
      },
      "source": [
        "# 언어모델용 Dataset/DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luuJeDQHFm8F"
      },
      "outputs": [],
      "source": [
        "# 데이터셋\n",
        "ids_full = sp.encode(NORM_TXT.read_text(encoding=\"utf-8\"), out_type=int)\n",
        "\n",
        "# LMDataset\n",
        "class LMDataset(Dataset):\n",
        "    def __init__(self, ids, block=256, indices=None):\n",
        "        self.ids = torch.tensor(ids, dtype=torch.long)   # 전체 토큰 시퀀스를 int64 텐서로 고정(1D)\n",
        "        self.block = block                               # 입력 시퀀스 길이(컨텍스트 길이)\n",
        "        N = len(self.ids) - block - 1                    # 만들 수 있는 샘플 수: 시작 i의 최대 개수\n",
        "        if indices is None:\n",
        "            self.indices = torch.arange(N)               # 기본: 0..N-1 모든 시작 위치 사용\n",
        "        else:\n",
        "            self.indices = indices                       # 외부에서 전달된 시작 인덱스 집합 사용(샘플 서브셋/샘플링용)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)                         # 샘플 개수는 시작 인덱스의 개수와 동일\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        i = int(self.indices[idx])                       # idx번째 샘플의 시작 위치 i\n",
        "        x = self.ids[i:i+self.block]                     # 입력 시퀀스 x: 길이 block\n",
        "        y = self.ids[i+1:i+self.block+1]                 # 정답 시퀀스 y: x를 한 토큰 우측으로 시프트한 다음 토큰들\n",
        "        return x, y\n",
        "block_size, batch_size = 256, 64\n",
        "N = len(ids_full) - block_size - 1\n",
        "all_idx = torch.randperm(N)\n",
        "n_tr = int(N*0.9)\n",
        "train_idx, val_idx = all_idx[:n_tr], all_idx[n_tr:]\n",
        "\n",
        "train_ds = LMDataset(ids_full, block_size, train_idx)\n",
        "val_ds   = LMDataset(ids_full, block_size, val_idx)\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  drop_last=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, drop_last=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnLhbwisFm8F"
      },
      "source": [
        "# 모델\n",
        "- LSTM 은 순차 문맥을 인코딩\n",
        "- nn.MultiheadAttention(batch_first=True) 로 자기어텐션을 적용\n",
        "- Causal mask 로 미래 토큰 차단 (언어모델 특성 유지)\n",
        "- 잔차(residual) + LayerNorm 으로 안정화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9KRQtN3Fm8F"
      },
      "outputs": [],
      "source": [
        "# 모델\n",
        "class LSTMAttnLM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb=384, hid=384, layers=2, heads=6, drop=0.3):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb)\n",
        "        self.lstm = nn.LSTM(emb, hid, num_layers=layers, batch_first=True, dropout=drop)\n",
        "        self.attn = nn.MultiheadAttention(hid, heads, dropout=drop, batch_first=True)\n",
        "        self.ln = nn.LayerNorm(hid)\n",
        "        self.fc = nn.Linear(hid, vocab_size, bias=False)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "        # weight tying\n",
        "        if emb != hid:\n",
        "            self.proj = nn.Linear(hid, emb, bias=False)\n",
        "        else:\n",
        "            self.proj = nn.Identity()\n",
        "        # fc.weight shares with embedding\n",
        "        self.fc.weight = self.emb.weight\n",
        "\n",
        "    def forward(self, x):\n",
        "        h,_ = self.lstm(self.emb(x))           # (B,T,H)\n",
        "        T = h.size(1)\n",
        "        mask = torch.full((T,T), float(\"-inf\"), device=h.device).triu(1)\n",
        "        a,_ = self.attn(h, h, h, attn_mask=mask, need_weights=False)\n",
        "        y = self.ln(h + self.drop(a))\n",
        "        y = self.proj(y)                       # to emb dim if needed\n",
        "        return self.fc(y)\n",
        "\n",
        "vocab_size = sp.get_piece_size()\n",
        "model = LSTMAttnLM(vocab_size).to(device)\n",
        "sum(p.numel() for p in model.parameters())/1e6\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GdmpqxuFm8F"
      },
      "source": [
        "# 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB76VPtZFm8F"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snJ_j0X9Fm8F"
      },
      "outputs": [],
      "source": [
        "def run_epoch(loader, train=True):\n",
        "    model.train(train)\n",
        "    total_loss, total_tokens = 0.0, 0\n",
        "    for x,y in loader:\n",
        "        x,y = x.to(device), y.to(device)\n",
        "        if train: optimizer.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits.reshape(-1, vocab_size), y.reshape(-1))\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "        total_loss += loss.item() * y.numel()         # 토큰 수로 집계\n",
        "        total_tokens += y.numel()\n",
        "    if train: scheduler.step()\n",
        "    return total_loss / max(1, total_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a72Gz8N7Fm8F"
      },
      "outputs": [],
      "source": [
        "# 학습\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def run_epoch(loader, train=True):\n",
        "    model.train(train)\n",
        "    total, n = 0.0, 0\n",
        "    for x,y in loader:\n",
        "        x,y = x.to(device), y.to(device)\n",
        "        if train: optimizer.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits.reshape(-1, vocab_size), y.reshape(-1))\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "        total += loss.item()*x.size(0); n += x.size(0)\n",
        "    return total/max(1,n)\n",
        "\n",
        "best = 1e9\n",
        "for ep in range(1, 10):  # 데모: 5 epoch\n",
        "    tr = run_epoch(train_loader, True)\n",
        "    va = run_epoch(val_loader, False)\n",
        "    if va < best:\n",
        "        best = va\n",
        "        torch.save(model.state_dict(), DATA_DIR/\"best_lstm_attn.pt\")\n",
        "    print(f\"[{ep:02d}] train_ce={tr:.4f}  val_ce={va:.4f}\")\n",
        "torch.save(model.state_dict(), DATA_DIR/\"best_lstm_attn.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqS5mqOiFm8G"
      },
      "source": [
        "# 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRk99GVfFm8G"
      },
      "outputs": [],
      "source": [
        "def sample(model, sp, prompt, max_new_tokens=300, temperature=0.9, top_k=50):\n",
        "    model.eval()\n",
        "    x = torch.tensor(sp.encode(prompt, out_type=int), dtype=torch.long, device=device).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_new_tokens):\n",
        "            x_cond = x[:, -block_size:]               # 길이 제한\n",
        "            logits = model(x_cond)                    # (1, T, V)\n",
        "            last = logits[:, -1, :] / max(1e-6, temperature)\n",
        "            if top_k:\n",
        "                v, _ = torch.topk(last, k=min(top_k, last.size(-1)))\n",
        "                last = torch.where(last < v[:, -1].unsqueeze(-1), torch.full_like(last, -1e10), last)\n",
        "            probs = torch.softmax(last, dim=-1)\n",
        "            next_id = torch.multinomial(probs, 1)     # (1,1)\n",
        "            x = torch.cat([x, next_id], dim=1)\n",
        "    return sp.decode(x[0].tolist())\n",
        "\n",
        "model.load_state_dict(torch.load(DATA_DIR/\"best_lstm_attn.pt\", map_location=device))\n",
        "print(sample(model, sp, \"성춘향은\", max_new_tokens=300, temperature=0.9, top_k=50))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVZ-oQrWFm8G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWGo2FnpFm8G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdnGWs5PFm8G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bz_gVnMXFm8G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9BILQwgFm8G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXdw8CiZFm8G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zR7plG4tFm8G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUBrRylhFm8G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U73h-A8oFm8G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTC4CxlmFm8G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8V513lmFm8G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}