{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NR8E6URZK1X3"
   },
   "source": [
    "# ê¸°ë³¸í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-yLT1RFEeQgm"
   },
   "outputs": [],
   "source": [
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "esrEO7yteQgm"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "HF_KEY = userdata.get(\"HF_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPGOz6I1JkBj"
   },
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "huggingface_hub.login(HF_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_XVtfyiLiAi"
   },
   "source": [
    "# ëª¨ë¸ ë¡œë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NEBCNVjffATu"
   },
   "outputs": [],
   "source": [
    "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo langchain-community pypdf langchain_huggingface faiss-cpu\n",
    "!pip install --no-deps unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:10:54.378487Z",
     "iopub.status.busy": "2025-10-10T04:10:54.378371Z",
     "iopub.status.idle": "2025-10-10T04:11:01.553459Z",
     "shell.execute_reply": "2025-10-10T04:11:01.553087Z",
     "shell.execute_reply.started": "2025-10-10T04:10:54.378476Z"
    },
    "id": "1oQenpTCPMyh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastModel\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:11:01.553922Z",
     "iopub.status.busy": "2025-10-10T04:11:01.553834Z",
     "iopub.status.idle": "2025-10-10T04:11:01.555567Z",
     "shell.execute_reply": "2025-10-10T04:11:01.555315Z",
     "shell.execute_reply.started": "2025-10-10T04:11:01.553914Z"
    },
    "id": "CU6jp1fqeQgn"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:11:01.555914Z",
     "iopub.status.busy": "2025-10-10T04:11:01.555838Z",
     "iopub.status.idle": "2025-10-10T04:11:14.175229Z",
     "shell.execute_reply": "2025-10-10T04:11:14.174824Z",
     "shell.execute_reply.started": "2025-10-10T04:11:01.555907Z"
    },
    "id": "btydbHNpeQgn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.1: Fast Gemma3 patching. Transformers: 4.55.4. vLLM: 0.10.2rc2.dev98+ge599e2c65.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4090. Num GPUs = 2. Max memory: 23.484 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"unsloth/gemma-3-4b-it\",\n",
    "    max_seq_length = 1024*5, # Choose any for long context!\n",
    "    load_in_4bit = True,  # 4 bit quantization to reduce memory\n",
    "    # device_map = {\"\": device}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom ChatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:13:22.722887Z",
     "iopub.status.busy": "2025-10-10T04:13:22.722733Z",
     "iopub.status.idle": "2025-10-10T04:13:22.724785Z",
     "shell.execute_reply": "2025-10-10T04:13:22.724554Z",
     "shell.execute_reply.started": "2025-10-10T04:13:22.722878Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Any, Dict\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.outputs import ChatResult, ChatGeneration\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:11:14.277831Z",
     "iopub.status.busy": "2025-10-10T04:11:14.277746Z",
     "iopub.status.idle": "2025-10-10T04:11:14.282813Z",
     "shell.execute_reply": "2025-10-10T04:11:14.282506Z",
     "shell.execute_reply.started": "2025-10-10T04:11:14.277822Z"
    }
   },
   "outputs": [],
   "source": [
    "class GemmaChatModel(BaseChatModel):\n",
    "    def __init__(self, model, tokenizer, max_tokens: int = 512, do_sample: bool = True, temperature: float = 0.7, top_p: float = 0.9):\n",
    "        super().__init__()\n",
    "        object.__setattr__(self, \"model\", model)\n",
    "        object.__setattr__(self, \"tokenizer\", tokenizer)\n",
    "        object.__setattr__(self, \"max_tokens\", max_tokens)\n",
    "        object.__setattr__(self, \"do_sample\", do_sample)\n",
    "        object.__setattr__(self, \"temperature\", temperature)\n",
    "        object.__setattr__(self, \"top_p\", top_p)\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"gemma-chat\"\n",
    "\n",
    "    def _format_messages(self, messages: List[Any]) -> str:\n",
    "        prompt = \"\"\n",
    "        for message in messages:\n",
    "            if isinstance(message, SystemMessage):\n",
    "                prompt += f\"<|system|>\\n{message.content}</s>\\n\"\n",
    "            elif isinstance(message, HumanMessage):\n",
    "                prompt += f\"<|user|>\\n{message.content}</s>\\n\"\n",
    "            elif isinstance(message, AIMessage):\n",
    "                prompt += f\"<|assistant|>\\n{message.content}</s>\\n\"\n",
    "        prompt += \"<|assistant|>\\n\"\n",
    "        return prompt\n",
    "\n",
    "    def _generate(self, messages: List[Any], **kwargs) -> ChatResult:\n",
    "        prompt = self._format_messages(messages)\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=self.max_tokens,\n",
    "                do_sample=kwargs.get(\"do_sample\", self.do_sample),\n",
    "                temperature=kwargs.get(\"temperature\", self.temperature),\n",
    "                top_p=kwargs.get(\"top_p\", self.top_p),\n",
    "                eos_token_id=self.tokenizer.eos_token_id,\n",
    "            )\n",
    "\n",
    "        decoded = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        response = decoded.split(\"<|assistant|>\\n\")[-1].strip()\n",
    "\n",
    "        return ChatResult(generations=[ChatGeneration(message=AIMessage(content=response))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:11:14.283203Z",
     "iopub.status.busy": "2025-10-10T04:11:14.283111Z",
     "iopub.status.idle": "2025-10-10T04:11:14.306825Z",
     "shell.execute_reply": "2025-10-10T04:11:14.306388Z",
     "shell.execute_reply.started": "2025-10-10T04:11:14.283194Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = GemmaChatModel(model=model, tokenizer=tokenizer, max_tokens=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# íˆ´ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:13:02.989869Z",
     "iopub.status.busy": "2025-10-10T04:13:02.989699Z",
     "iopub.status.idle": "2025-10-10T04:13:02.991606Z",
     "shell.execute_reply": "2025-10-10T04:13:02.991384Z",
     "shell.execute_reply.started": "2025-10-10T04:13:02.989858Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_weather(city: str) -> str:\n",
    "    return f\"{city}: ë§‘ìŒ, 25â„ƒ (ë°ëª¨)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:13:03.173870Z",
     "iopub.status.busy": "2025-10-10T04:13:03.173693Z",
     "iopub.status.idle": "2025-10-10T04:13:03.175625Z",
     "shell.execute_reply": "2025-10-10T04:13:03.175398Z",
     "shell.execute_reply.started": "2025-10-10T04:13:03.173858Z"
    }
   },
   "outputs": [],
   "source": [
    "def add(a: float, b: float) -> float:\n",
    "    return float(a) + float(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:13:26.448454Z",
     "iopub.status.busy": "2025-10-10T04:13:26.448285Z",
     "iopub.status.idle": "2025-10-10T04:13:26.450666Z",
     "shell.execute_reply": "2025-10-10T04:13:26.450404Z",
     "shell.execute_reply.started": "2025-10-10T04:13:26.448442Z"
    }
   },
   "outputs": [],
   "source": [
    "TOOLS: Dict[str, Dict[str, Any]] = {\n",
    "    \"get_weather\": {\n",
    "        \"description\": \"ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì¡°íšŒ\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\"city\": {\"type\": \"string\"}},\n",
    "            \"required\": [\"city\"],\n",
    "        },\n",
    "    },\n",
    "    \"add\": {\n",
    "        \"description\": \"ë‘ ìˆ˜ë¥¼ ë”í•œë‹¤\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\"a\": {\"type\": \"number\"}, \"b\": {\"type\": \"number\"}},\n",
    "            \"required\": [\"a\", \"b\"],\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:13:27.347096Z",
     "iopub.status.busy": "2025-10-10T04:13:27.346888Z",
     "iopub.status.idle": "2025-10-10T04:13:27.348895Z",
     "shell.execute_reply": "2025-10-10T04:13:27.348641Z",
     "shell.execute_reply.started": "2025-10-10T04:13:27.347079Z"
    }
   },
   "outputs": [],
   "source": [
    "TOOL_FUNCS = {\n",
    "    \"get_weather\": get_weather,\n",
    "    \"add\": add,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt & Chain ì •ì˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tool chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:14:10.355017Z",
     "iopub.status.busy": "2025-10-10T04:14:10.354872Z",
     "iopub.status.idle": "2025-10-10T04:14:10.356982Z",
     "shell.execute_reply": "2025-10-10T04:14:10.356716Z",
     "shell.execute_reply.started": "2025-10-10T04:14:10.355008Z"
    }
   },
   "outputs": [],
   "source": [
    "## param : tool_names, tool_schema, input\n",
    "select_instruct = \"\"\"\\\n",
    "You are a tool router. Read the user's request and decide whether to call a tool.\n",
    "Return ONLY one JSON object and NOTHING ELSE (no code fences, no commentary).\n",
    "\n",
    "Strict output JSON (one object):\n",
    "{{\n",
    "  \"tool\": \"<one of: {tool_names} | none>\",\n",
    "  \"args\": <object>\n",
    "}}\n",
    "\n",
    "Global rules:\n",
    "- Use ONLY tools defined in the TOOL SCHEMA below. If nothing matches, set \"tool\" to \"none\" and \"args\" to {{}}.\n",
    "- Output must be valid JSON with double quotes and no trailing commas.\n",
    "- Only choose a tool if:\n",
    "  (a) the request clearly matches the toolâ€™s description/purpose, AND\n",
    "  (b) you can supply ALL required parameters from the user input.\n",
    "- Do NOT invent, guess, or hallucinate parameter values. If a required value is missing/unclear, choose \"none\".\n",
    "- Conform exactly to the selected tool's parameter schema (names, types, enums). Do not add extra keys not in the schema.\n",
    "- If multiple tools could work, prefer the most specific one that best matches the userâ€™s intent.\n",
    "- Keep numbers as numbers, booleans as booleans, arrays as arrays, strings as strings. Do not convert types arbitrarily.\n",
    "- Preserve user-provided text as-is (do not translate or rewrite); only extract values for \"args\".\n",
    "- Think silently; DO NOT include chain-of-thought or explanations in the output.\n",
    "\n",
    "TOOL SCHEMA (names, descriptions, and JSON parameter schemas):\n",
    "{tool_schema}\n",
    "\n",
    "Examples (for style only; do NOT copy literally):\n",
    "User: What's the weather in Paris?\n",
    "Output:\n",
    "{{\"tool\":\"get_weather\",\"args\":{{\"city\":\"Paris\"}}}}\n",
    "\n",
    "User: add 7.5 and 2\n",
    "Output:\n",
    "{{\"tool\":\"add\",\"args\":{{\"a\":7.5,\"b\":2}}}}\n",
    "\n",
    "User: Tell me a joke\n",
    "Output:\n",
    "{{\"tool\":\"none\",\"args\":{{}}}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:14:10.637205Z",
     "iopub.status.busy": "2025-10-10T04:14:10.637050Z",
     "iopub.status.idle": "2025-10-10T04:14:10.639044Z",
     "shell.execute_reply": "2025-10-10T04:14:10.638818Z",
     "shell.execute_reply.started": "2025-10-10T04:14:10.637196Z"
    }
   },
   "outputs": [],
   "source": [
    "select_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", select_instruct),\n",
    "    (\"human\", \"Now produce the JSON for this user request:\\n{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:14:19.264763Z",
     "iopub.status.busy": "2025-10-10T04:14:19.264613Z",
     "iopub.status.idle": "2025-10-10T04:14:19.266355Z",
     "shell.execute_reply": "2025-10-10T04:14:19.266127Z",
     "shell.execute_reply.started": "2025-10-10T04:14:19.264754Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = JsonOutputParser()  # {\"tool\": str, \"args\": dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:14:20.367654Z",
     "iopub.status.busy": "2025-10-10T04:14:20.367504Z",
     "iopub.status.idle": "2025-10-10T04:14:20.369338Z",
     "shell.execute_reply": "2025-10-10T04:14:20.369093Z",
     "shell.execute_reply.started": "2025-10-10T04:14:20.367645Z"
    }
   },
   "outputs": [],
   "source": [
    "select_tool_chain = select_prompt | llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## question chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:16:06.920884Z",
     "iopub.status.busy": "2025-10-10T04:16:06.920751Z",
     "iopub.status.idle": "2025-10-10T04:16:06.922633Z",
     "shell.execute_reply": "2025-10-10T04:16:06.922411Z",
     "shell.execute_reply.started": "2025-10-10T04:16:06.920876Z"
    }
   },
   "outputs": [],
   "source": [
    "question_instruct = \"\"\"\\\n",
    "You must answer concisely and accurately in korean.\n",
    "\n",
    "Tool result:\n",
    "{observation}\n",
    "\n",
    "Instructions:\n",
    "- If the Tool result is NON-EMPTY, produce ONE short paragraph grounded ONLY in that result. Do not contradict it. If it is incomplete or conflicting, state what is missing and answer only with what can be supported.\n",
    "- If the Tool result is EMPTY, answer directly from your knowledge. If you do not know, say \"I don't know.\" Do NOT invent or guess facts.\n",
    "- Do NOT include analysis, chain-of-thought, meta commentary, or mentions of tools/pipelines. Output only the final answer.\n",
    "- Keep it concise (about 1â€“5 sentences) unless the user explicitly requested another format.\n",
    "- If the user asked for a specific format (e.g., code or bullet points), follow it; otherwise use plain text.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:16:07.004859Z",
     "iopub.status.busy": "2025-10-10T04:16:07.004704Z",
     "iopub.status.idle": "2025-10-10T04:16:07.006629Z",
     "shell.execute_reply": "2025-10-10T04:16:07.006397Z",
     "shell.execute_reply.started": "2025-10-10T04:16:07.004850Z"
    }
   },
   "outputs": [],
   "source": [
    "question_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", question_instruct),\n",
    "    (\"human\", \"User question:\\n{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:16:07.341581Z",
     "iopub.status.busy": "2025-10-10T04:16:07.341437Z",
     "iopub.status.idle": "2025-10-10T04:16:07.343086Z",
     "shell.execute_reply": "2025-10-10T04:16:07.342888Z",
     "shell.execute_reply.started": "2025-10-10T04:16:07.341573Z"
    }
   },
   "outputs": [],
   "source": [
    "question_chain = question_prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph Smithy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![langgraph_example](res/langgraph_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:25:18.867057Z",
     "iopub.status.busy": "2025-10-10T04:25:18.866913Z",
     "iopub.status.idle": "2025-10-10T04:25:18.868659Z",
     "shell.execute_reply": "2025-10-10T04:25:18.868405Z",
     "shell.execute_reply.started": "2025-10-10T04:25:18.867049Z"
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Optional, Dict, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ìƒíƒœ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:27:55.037751Z",
     "iopub.status.busy": "2025-10-10T04:27:55.037588Z",
     "iopub.status.idle": "2025-10-10T04:27:55.039869Z",
     "shell.execute_reply": "2025-10-10T04:27:55.039608Z",
     "shell.execute_reply.started": "2025-10-10T04:27:55.037740Z"
    }
   },
   "outputs": [],
   "source": [
    "class StateToolQA(TypedDict):\n",
    "    input: str\n",
    "    tool_schema: Dict[str, Any]\n",
    "    tool_names: str\n",
    "    selection: Dict[str, Any]\n",
    "    observation: Optional[Any]\n",
    "    answer: Optional[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:27:55.241083Z",
     "iopub.status.busy": "2025-10-10T04:27:55.240886Z",
     "iopub.status.idle": "2025-10-10T04:27:55.243385Z",
     "shell.execute_reply": "2025-10-10T04:27:55.242923Z",
     "shell.execute_reply.started": "2025-10-10T04:27:55.241064Z"
    }
   },
   "outputs": [],
   "source": [
    "state_toolqa = StateToolQA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tool select ë…¸ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:28:02.630870Z",
     "iopub.status.busy": "2025-10-10T04:28:02.630725Z",
     "iopub.status.idle": "2025-10-10T04:28:02.633357Z",
     "shell.execute_reply": "2025-10-10T04:28:02.633073Z",
     "shell.execute_reply.started": "2025-10-10T04:28:02.630861Z"
    }
   },
   "outputs": [],
   "source": [
    "def node_tool_select(state: StateToolQA) -> StateToolQA:\n",
    "    print(f\"[+] node_tool_select\\n{state}\")\n",
    "    selection = select_tool_chain.invoke({\n",
    "        \"input\": state[\"input\"],\n",
    "        \"tool_schema\": state.get(\"tool_schema\", TOOLS),\n",
    "        \"tool_names\": state.get(\"tool_names\", \", \".join(TOOLS.keys())),\n",
    "    })\n",
    "    print(f\"[+] node_tool_select\\n{selection}\")\n",
    "    return {**state, \"selection\": selection}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:52:37.062676Z",
     "iopub.status.busy": "2025-10-10T04:52:37.062526Z",
     "iopub.status.idle": "2025-10-10T04:52:37.065083Z",
     "shell.execute_reply": "2025-10-10T04:52:37.064869Z",
     "shell.execute_reply.started": "2025-10-10T04:52:37.062667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?',\n",
       " 'tool_schema': {'get_weather': {'description': 'ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì¡°íšŒ',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'city': {'type': 'string'}},\n",
       "    'required': ['city']}},\n",
       "  'add': {'description': 'ë‘ ìˆ˜ë¥¼ ë”í•œë‹¤',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}},\n",
       "    'required': ['a', 'b']}}},\n",
       " 'tool_names': 'get_weather, add',\n",
       " 'selection': {'tool': 'none', 'args': {}}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_toolqa = {**state_toolqa, \"input\": \"ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?\", \"tool_schema\": TOOLS, \"tool_names\": ', '.join(TOOLS.keys())}\n",
    "state_toolqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:52:37.272496Z",
     "iopub.status.busy": "2025-10-10T04:52:37.272313Z",
     "iopub.status.idle": "2025-10-10T04:52:38.092597Z",
     "shell.execute_reply": "2025-10-10T04:52:38.092329Z",
     "shell.execute_reply.started": "2025-10-10T04:52:37.272484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] node_tool_select\n",
      "{'input': 'ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?', 'tool_schema': {'get_weather': {'description': 'ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì¡°íšŒ', 'parameters': {'type': 'object', 'properties': {'city': {'type': 'string'}}, 'required': ['city']}}, 'add': {'description': 'ë‘ ìˆ˜ë¥¼ ë”í•œë‹¤', 'parameters': {'type': 'object', 'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}}, 'required': ['a', 'b']}}}, 'tool_names': 'get_weather, add', 'selection': {'tool': 'none', 'args': {}}}\n",
      "[+] node_tool_select\n",
      "{'tool': 'get_weather', 'args': {'city': 'ì„œìš¸'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?',\n",
       " 'tool_schema': {'get_weather': {'description': 'ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì¡°íšŒ',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'city': {'type': 'string'}},\n",
       "    'required': ['city']}},\n",
       "  'add': {'description': 'ë‘ ìˆ˜ë¥¼ ë”í•œë‹¤',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}},\n",
       "    'required': ['a', 'b']}}},\n",
       " 'tool_names': 'get_weather, add',\n",
       " 'selection': {'tool': 'get_weather', 'args': {'city': 'ì„œìš¸'}}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_toolqa = node_tool_select(state_toolqa)\n",
    "state_toolqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:38:55.578838Z",
     "iopub.status.busy": "2025-10-10T04:38:55.578690Z",
     "iopub.status.idle": "2025-10-10T04:38:56.438978Z",
     "shell.execute_reply": "2025-10-10T04:38:56.438730Z",
     "shell.execute_reply.started": "2025-10-10T04:38:55.578829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] node_tool_select\n",
      "{'input': '2ì™€ 3ì„ ë”í•œ ê²°ê³¼ëŠ”?', 'tool_schema': {'get_weather': {'description': 'ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì¡°íšŒ', 'parameters': {'type': 'object', 'properties': {'city': {'type': 'string'}}, 'required': ['city']}}, 'add': {'description': 'ë‘ ìˆ˜ë¥¼ ë”í•œë‹¤', 'parameters': {'type': 'object', 'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}}, 'required': ['a', 'b']}}}, 'tool_names': 'get_weather, add', 'selection': {'tool': 'get_weather', 'args': {'city': 'ì„œìš¸'}}}\n",
      "[+] node_tool_select\n",
      "{'tool': 'add', 'args': {'a': 2, 'b': 3}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '2ì™€ 3ì„ ë”í•œ ê²°ê³¼ëŠ”?',\n",
       " 'tool_schema': {'get_weather': {'description': 'ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì¡°íšŒ',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'city': {'type': 'string'}},\n",
       "    'required': ['city']}},\n",
       "  'add': {'description': 'ë‘ ìˆ˜ë¥¼ ë”í•œë‹¤',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}},\n",
       "    'required': ['a', 'b']}}},\n",
       " 'tool_names': 'get_weather, add',\n",
       " 'selection': {'tool': 'add', 'args': {'a': 2, 'b': 3}}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_toolqa = {**state_toolqa, \"input\": \"2ì™€ 3ì„ ë”í•œ ê²°ê³¼ëŠ”?\", \"tool_schema\": TOOLS, \"tool_names\": ', '.join(TOOLS.keys())}\n",
    "state_toolqa = node_tool_select(state_toolqa)\n",
    "state_toolqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:39:30.163248Z",
     "iopub.status.busy": "2025-10-10T04:39:30.163092Z",
     "iopub.status.idle": "2025-10-10T04:39:30.811501Z",
     "shell.execute_reply": "2025-10-10T04:39:30.811170Z",
     "shell.execute_reply.started": "2025-10-10T04:39:30.163239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] node_tool_select\n",
      "{'input': 'ì¢‹ì€ íšŒì˜ ì•„ì´ìŠ¤ë¸Œë ˆì´ì»¤ ì•Œë ¤ì¤˜', 'tool_schema': {'get_weather': {'description': 'ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì¡°íšŒ', 'parameters': {'type': 'object', 'properties': {'city': {'type': 'string'}}, 'required': ['city']}}, 'add': {'description': 'ë‘ ìˆ˜ë¥¼ ë”í•œë‹¤', 'parameters': {'type': 'object', 'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}}, 'required': ['a', 'b']}}}, 'tool_names': 'get_weather, add', 'selection': {'tool': 'add', 'args': {'a': 2, 'b': 3}}}\n",
      "[+] node_tool_select\n",
      "{'tool': 'none', 'args': {}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'ì¢‹ì€ íšŒì˜ ì•„ì´ìŠ¤ë¸Œë ˆì´ì»¤ ì•Œë ¤ì¤˜',\n",
       " 'tool_schema': {'get_weather': {'description': 'ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì¡°íšŒ',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'city': {'type': 'string'}},\n",
       "    'required': ['city']}},\n",
       "  'add': {'description': 'ë‘ ìˆ˜ë¥¼ ë”í•œë‹¤',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}},\n",
       "    'required': ['a', 'b']}}},\n",
       " 'tool_names': 'get_weather, add',\n",
       " 'selection': {'tool': 'none', 'args': {}}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_toolqa = {**state_toolqa, \"input\": \"ì¢‹ì€ íšŒì˜ ì•„ì´ìŠ¤ë¸Œë ˆì´ì»¤ ì•Œë ¤ì¤˜\", \"tool_schema\": TOOLS, \"tool_names\": ', '.join(TOOLS.keys())}\n",
    "state_toolqa = node_tool_select(state_toolqa)\n",
    "state_toolqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tool ì‹¤í–‰ ë…¸ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:52:49.162321Z",
     "iopub.status.busy": "2025-10-10T04:52:49.162126Z",
     "iopub.status.idle": "2025-10-10T04:52:49.164826Z",
     "shell.execute_reply": "2025-10-10T04:52:49.164508Z",
     "shell.execute_reply.started": "2025-10-10T04:52:49.162310Z"
    }
   },
   "outputs": [],
   "source": [
    "def node_tool_call(state: StateToolQA) -> StateToolQA:\n",
    "    print(f\"[+] node_tool_call\\n{state}\")\n",
    "    selection = state.get(\"selection\", {}) or {}\n",
    "    tool = selection.get(\"tool\", \"none\")\n",
    "    args = selection.get(\"args\") or {}\n",
    "\n",
    "    if tool not in TOOL_FUNCS:\n",
    "        return {**state, \"observation\": None}\n",
    "\n",
    "    try:\n",
    "        result = TOOL_FUNCS[tool](**args)\n",
    "    except Exception as e:\n",
    "        result = f\"TOOL_ERROR: {e}\"\n",
    "    return {**state, \"observation\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:52:49.442659Z",
     "iopub.status.busy": "2025-10-10T04:52:49.442494Z",
     "iopub.status.idle": "2025-10-10T04:52:49.444964Z",
     "shell.execute_reply": "2025-10-10T04:52:49.444715Z",
     "shell.execute_reply.started": "2025-10-10T04:52:49.442649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?',\n",
       " 'tool_schema': {'get_weather': {'description': 'ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì¡°íšŒ',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'city': {'type': 'string'}},\n",
       "    'required': ['city']}},\n",
       "  'add': {'description': 'ë‘ ìˆ˜ë¥¼ ë”í•œë‹¤',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}},\n",
       "    'required': ['a', 'b']}}},\n",
       " 'tool_names': 'get_weather, add',\n",
       " 'selection': {'tool': 'get_weather', 'args': {'city': 'ì„œìš¸'}}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_toolqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:53:14.044716Z",
     "iopub.status.busy": "2025-10-10T04:53:14.044561Z",
     "iopub.status.idle": "2025-10-10T04:53:14.047208Z",
     "shell.execute_reply": "2025-10-10T04:53:14.047008Z",
     "shell.execute_reply.started": "2025-10-10T04:53:14.044707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] node_tool_call\n",
      "{'input': 'ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?', 'tool_schema': {'get_weather': {'description': 'ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì¡°íšŒ', 'parameters': {'type': 'object', 'properties': {'city': {'type': 'string'}}, 'required': ['city']}}, 'add': {'description': 'ë‘ ìˆ˜ë¥¼ ë”í•œë‹¤', 'parameters': {'type': 'object', 'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}}, 'required': ['a', 'b']}}}, 'tool_names': 'get_weather, add', 'selection': {'tool': 'get_weather', 'args': {'city': 'ì„œìš¸'}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?',\n",
       " 'tool_schema': {'get_weather': {'description': 'ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì¡°íšŒ',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'city': {'type': 'string'}},\n",
       "    'required': ['city']}},\n",
       "  'add': {'description': 'ë‘ ìˆ˜ë¥¼ ë”í•œë‹¤',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}},\n",
       "    'required': ['a', 'b']}}},\n",
       " 'tool_names': 'get_weather, add',\n",
       " 'selection': {'tool': 'get_weather', 'args': {'city': 'ì„œìš¸'}},\n",
       " 'observation': 'ì„œìš¸: ë§‘ìŒ, 25â„ƒ (ë°ëª¨)'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_toolqa = node_tool_call(state_toolqa)\n",
    "state_toolqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## question ë…¸ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:54:30.790692Z",
     "iopub.status.busy": "2025-10-10T04:54:30.790543Z",
     "iopub.status.idle": "2025-10-10T04:54:30.792813Z",
     "shell.execute_reply": "2025-10-10T04:54:30.792584Z",
     "shell.execute_reply.started": "2025-10-10T04:54:30.790683Z"
    }
   },
   "outputs": [],
   "source": [
    "def node_question(state: StateToolQA) -> StateToolQA:\n",
    "    print(f\"[+] node_question\\n{state}\")\n",
    "    msg = question_chain.invoke({\n",
    "        \"input\": state[\"input\"],\n",
    "        \"observation\": state.get(\"observation\")\n",
    "    })\n",
    "    content = getattr(msg, \"content\", str(msg))\n",
    "    return {**state, \"answer\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:55:04.513196Z",
     "iopub.status.busy": "2025-10-10T04:55:04.513041Z",
     "iopub.status.idle": "2025-10-10T04:55:04.515662Z",
     "shell.execute_reply": "2025-10-10T04:55:04.515403Z",
     "shell.execute_reply.started": "2025-10-10T04:55:04.513178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?',\n",
       " 'tool_schema': {'get_weather': {'description': 'ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì¡°íšŒ',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'city': {'type': 'string'}},\n",
       "    'required': ['city']}},\n",
       "  'add': {'description': 'ë‘ ìˆ˜ë¥¼ ë”í•œë‹¤',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}},\n",
       "    'required': ['a', 'b']}}},\n",
       " 'tool_names': 'get_weather, add',\n",
       " 'selection': {'tool': 'get_weather', 'args': {'city': 'ì„œìš¸'}},\n",
       " 'observation': 'ì„œìš¸: ë§‘ìŒ, 25â„ƒ (ë°ëª¨)'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_toolqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:55:20.489790Z",
     "iopub.status.busy": "2025-10-10T04:55:20.489640Z",
     "iopub.status.idle": "2025-10-10T04:55:21.092076Z",
     "shell.execute_reply": "2025-10-10T04:55:21.091770Z",
     "shell.execute_reply.started": "2025-10-10T04:55:20.489781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] node_question\n",
      "{'input': 'ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?', 'tool_schema': {'get_weather': {'description': 'ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì¡°íšŒ', 'parameters': {'type': 'object', 'properties': {'city': {'type': 'string'}}, 'required': ['city']}}, 'add': {'description': 'ë‘ ìˆ˜ë¥¼ ë”í•œë‹¤', 'parameters': {'type': 'object', 'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}}, 'required': ['a', 'b']}}}, 'tool_names': 'get_weather, add', 'selection': {'tool': 'get_weather', 'args': {'city': 'ì„œìš¸'}}, 'observation': 'ì„œìš¸: ë§‘ìŒ, 25â„ƒ (ë°ëª¨)'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?',\n",
       " 'tool_schema': {'get_weather': {'description': 'ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì¡°íšŒ',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'city': {'type': 'string'}},\n",
       "    'required': ['city']}},\n",
       "  'add': {'description': 'ë‘ ìˆ˜ë¥¼ ë”í•œë‹¤',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}},\n",
       "    'required': ['a', 'b']}}},\n",
       " 'tool_names': 'get_weather, add',\n",
       " 'selection': {'tool': 'get_weather', 'args': {'city': 'ì„œìš¸'}},\n",
       " 'observation': 'ì„œìš¸: ë§‘ìŒ, 25â„ƒ (ë°ëª¨)',\n",
       " 'answer': 'ì„œìš¸ì€ ë§‘ê³ , í˜„ì¬ 25ë„ì…ë‹ˆë‹¤.'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_toolqa = node_question(state_toolqa)\n",
    "state_toolqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
