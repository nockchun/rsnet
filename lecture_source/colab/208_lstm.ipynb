{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR8E6URZK1X3"
      },
      "source": [
        "# 기본환경 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMBhxG6rZEx_"
      },
      "outputs": [],
      "source": [
        "import os, zipfile, urllib.request, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XdwoBpHZEx_"
      },
      "outputs": [],
      "source": [
        "# 하이퍼파라미터\n",
        "seq_len     = 24       # LSTM 입력 길이(과거 24시간)\n",
        "batch_size  = 32\n",
        "hidden_dim  = 64\n",
        "num_layers  = 3\n",
        "dropout     = 0.3\n",
        "lr          = 1e-4\n",
        "epochs      = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAY8BHN0ZEx_"
      },
      "outputs": [],
      "source": [
        "# 특성/타깃 선택\n",
        "feature_cols = [\"T\", \"RH\", \"AH\", \"PT08.S5(O3)\", \"NO2(GT)\", \"NO2(GT)\", \"PT08.S3(NOx)\"] # 입력에 쓸 컬럼 (온도, 상대습고, 절대습도)\n",
        "target_col   = \"T\" # 다음 시점 예측할 컬럼"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9crklxy7ZEx_"
      },
      "source": [
        "* UCI Air Quality 데이터 : 이탈리아의 한 도시 도로변(오염이 심한 지역)에 설치된 가스 멀티센서 장치에서 매 시각(hourly) 평균값을 수집한 시계열 데이터"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7I_Y3x0yZEx_"
      },
      "outputs": [],
      "source": [
        "# 데이터 경로/URL\n",
        "DATA_URL  = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00360/AirQualityUCI.zip\"\n",
        "DATA_DIR  = \"data/data_airquality\"\n",
        "ZIP_PATH  = os.path.join(DATA_DIR, \"AirQualityUCI.zip\")\n",
        "CSV_PATH  = os.path.join(DATA_DIR, \"AirQualityUCI.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Il4ZwAN3ZEyA"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLCD2ovYZEyA"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buxobVXVZEyA"
      },
      "outputs": [],
      "source": [
        "os.makedirs(DATA_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDjFQ_WlZEyA"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(CSV_PATH):\n",
        "    print(\"[INFO] Downloading dataset...\")\n",
        "    urllib.request.urlretrieve(DATA_URL, ZIP_PATH)\n",
        "    with zipfile.ZipFile(ZIP_PATH, \"r\") as zf:\n",
        "        with zf.open(\"AirQualityUCI.csv\") as f, open(CSV_PATH, \"wb\") as out:\n",
        "            out.write(f.read())\n",
        "    print(f\"[INFO] Saved: {CSV_PATH}\")\n",
        "else:\n",
        "    print(\"[INFO] CSV already exists:\", CSV_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0HirQYVZEyA"
      },
      "outputs": [],
      "source": [
        "# UCI 파일은 세미콜론(;) 구분, 소수점 ,(comma), -200은 결측치 코드\n",
        "df = pd.read_csv(\n",
        "    CSV_PATH,\n",
        "    sep=\";\",\n",
        "    decimal=\",\",\n",
        "    na_values=-200,\n",
        "    dtype={\"Date\": \"string\", \"Time\": \"string\"},\n",
        "    low_memory=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pF18RM2UZEyA"
      },
      "outputs": [],
      "source": [
        "datetime = df[\"Date\"].str.strip() + \" \" + df[\"Time\"].str.strip()\n",
        "df[\"datetime\"] = pd.to_datetime(datetime, format=\"%d/%m/%Y %H.%M.%S\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JFm6nahZEyA"
      },
      "outputs": [],
      "source": [
        "df.drop(columns=[\"Date\", \"Time\"], inplace=True)\n",
        "df.sort_values(\"datetime\", inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DFUgKLbZEyA"
      },
      "source": [
        "# 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlCJaO4MZEyA"
      },
      "outputs": [],
      "source": [
        "# 전부 NaN인 컬럼 제거(파일 끝의 빈 컬럼 등)\n",
        "df = df.dropna(axis=1, how=\"all\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4Z7GpDfZEyA"
      },
      "outputs": [],
      "source": [
        "# 결측치 처리(-200 -> NaN) 후 시계열 보간\n",
        "df = df.replace(-200, np.nan).sort_values(\"datetime\").reset_index(drop=True)\n",
        "df = df.ffill().bfill() # 각 컬럼별로 앞/뒤 값 복사(fill) 방식"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07Ni_u_LZEyA"
      },
      "outputs": [],
      "source": [
        "# 인덱스 설정\n",
        "df = df.set_index(\"datetime\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-07T08:49:10.360200Z",
          "iopub.status.busy": "2025-09-07T08:49:10.359880Z",
          "iopub.status.idle": "2025-09-07T08:49:10.365406Z",
          "shell.execute_reply": "2025-09-07T08:49:10.364776Z",
          "shell.execute_reply.started": "2025-09-07T08:49:10.360173Z"
        },
        "id": "WVWPVu9PZEyA"
      },
      "source": [
        "* UCI Air Quality 데이터\n",
        "    - Date (형식 DD/MM/YYYY)\n",
        "    - Time (형식 HH.MM.SS)\n",
        "    - CO(GT) – 기준 분석기로 측정한 CO 시평균 농도 (mg/m^3)\n",
        "    - PT08.S1(CO) – 센서 응답(주 대상: CO)\n",
        "    - NMHC(GT) – 기준 분석기 NMHC(비메탄 탄화수소) (µg/m^3)\n",
        "    - C6H6(GT) – 기준 분석기 벤젠 (µg/m^3)\n",
        "    - PT08.S2(NMHC) – 센서 응답(주 대상: NMHC)\n",
        "    - NOx(GT) – 기준 분석기 NOx (ppb)\n",
        "    - PT08.S3(NOx) – 센서 응답(주 대상: NOx)\n",
        "    - NO2(GT) – 기준 분석기 NO2 (µg/m^3)\n",
        "    - PT08.S4(NO2) – 센서 응답(주 대상: NO2)\n",
        "    - PT08.S5(O3) – 센서 응답(주 대상: O3)\n",
        "    - T – 온도 (°C)\n",
        "    - RH – 상대습도 (%)\n",
        "    - AH – 절대습도"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qq_WeY6KZEyA"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51Js2s8EZEyA"
      },
      "outputs": [],
      "source": [
        "# 사용 컬럼 미리 확인\n",
        "df[feature_cols + [target_col]].head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPbPN_rJZEyA"
      },
      "source": [
        "# 학습 데이터 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlpCzzMuZEyA"
      },
      "outputs": [],
      "source": [
        "# 다음 시점 예측(horizon=1)\n",
        "horizon = 1\n",
        "data = df[sorted(set(feature_cols + [target_col]))].copy()\n",
        "data[\"target\"] = data[target_col].shift(-horizon)\n",
        "data = data.dropna().reset_index(drop=False)  # 끝부분 NaN 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNooKMG2ZEyA"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jUQyU7_ZEyA"
      },
      "source": [
        "## 학습, 검증, 테스트 데이터 분리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSa6PP1EZEyA"
      },
      "outputs": [],
      "source": [
        "N = len(data)\n",
        "n_train = int(N * 0.7)\n",
        "n_val   = int(N * 0.1)\n",
        "n_test  = N - n_train - n_val\n",
        "n_train, n_val, n_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqqXuZ2wZEyA"
      },
      "outputs": [],
      "source": [
        "train_df = data.iloc[:n_train]\n",
        "val_df   = data.iloc[n_train:n_train+n_val]\n",
        "test_df  = data.iloc[n_train+n_val:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvyj7ReKZEyA"
      },
      "outputs": [],
      "source": [
        "X_train = train_df[feature_cols].values\n",
        "X_val   = val_df[feature_cols].values\n",
        "X_test  = test_df[feature_cols].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gySqp2riZEyA"
      },
      "outputs": [],
      "source": [
        "y_train = train_df[\"target\"].values.reshape(-1, 1)\n",
        "y_val   = val_df[\"target\"].values.reshape(-1, 1)\n",
        "y_test  = test_df[\"target\"].values.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXOqwgxqZEyA"
      },
      "source": [
        "## 표준화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv0DAIjuZEyA"
      },
      "outputs": [],
      "source": [
        "# 표준화(훈련셋 기준)\n",
        "x_scaler = StandardScaler().fit(X_train)\n",
        "y_scaler = StandardScaler().fit(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xausoQfpZEyA"
      },
      "outputs": [],
      "source": [
        "X_train_s = x_scaler.transform(X_train)\n",
        "X_val_s   = x_scaler.transform(X_val)\n",
        "X_test_s  = x_scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GS8qx1UoZEyA"
      },
      "outputs": [],
      "source": [
        "y_train_s = y_scaler.transform(y_train)\n",
        "y_val_s   = y_scaler.transform(y_val)\n",
        "y_test_s  = y_scaler.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WVrBs2lZEyA"
      },
      "outputs": [],
      "source": [
        "X_train_s.shape, y_train_s.shape, X_val_s.shape, y_val_s.shape, X_test_s.shape, y_test_s.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYRDYUXGZEyB"
      },
      "source": [
        "## Dataset 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrq9Sff_ZEyB"
      },
      "outputs": [],
      "source": [
        "class SeqDataset(Dataset):\n",
        "    \"\"\" (seq_len, features) 윈도우 -> 다음 시점 타깃 \"\"\"\n",
        "    def __init__(self, X, y, seq_len=24):\n",
        "        self.X = X\n",
        "        self.y = y.reshape(-1, 1) if y.ndim == 1 else y\n",
        "        self.seq_len = seq_len\n",
        "        self.idxs = [(i-seq_len, i) for i in range(seq_len, len(X))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idxs)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        s, e = self.idxs[i]\n",
        "        x = self.X[s:e]         # (L, F)\n",
        "        y = self.y[e]           # (1,)\n",
        "        return torch.from_numpy(x).float(), torch.from_numpy(y).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuUPl2_SZEyB"
      },
      "outputs": [],
      "source": [
        "train_ds = SeqDataset(X_train_s, y_train_s, seq_len=seq_len)\n",
        "val_ds   = SeqDataset(X_val_s,   y_val_s,   seq_len=seq_len)\n",
        "test_ds  = SeqDataset(X_test_s,  y_test_s,  seq_len=seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inzmoa4wZEyB"
      },
      "outputs": [],
      "source": [
        "len(train_ds), len(val_ds), len(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A20Gb8GZZEyB"
      },
      "source": [
        "## Dataloader 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiqQ8PO0ZEyB"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cbefhs6QZEyB"
      },
      "outputs": [],
      "source": [
        "next(iter(train_loader))[0].shape  # (batch, seq_len, features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDEJriafZEyB"
      },
      "source": [
        "# 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIZQfh-5ZEyB"
      },
      "outputs": [],
      "source": [
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giOm4fUEZEyB"
      },
      "outputs": [],
      "source": [
        "class LSTMRegressor(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64, num_layers=3, dropout=0.2):\n",
        "        super().__init__()\n",
        "        \"\"\"\n",
        "        * num_layers 2를 tensorflow로 구현\n",
        "        inputs = layers.Input(shape=(seq_len, input_size))\n",
        "        x = layers.LSTM(hidden_size, return_sequences=True, dropout=0.0, recurrent_dropout=0.0)(inputs)\n",
        "        x = layers.LSTM(hidden_size, return_sequences=True, dropout=0.0, recurrent_dropout=0.0)(x)\n",
        "        \"\"\"\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout,\n",
        "            batch_first=True # True이면 입력/출력의 형태가 (batch, seq_len, feature), False(기본값)이면 (seq_len, batch, feature)\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, L, F)\n",
        "        out, _ = self.lstm(x)\n",
        "        last = out[:, -1, :]          # 마지막 타임스텝\n",
        "        yhat = self.fc(last)          # (B, 1)\n",
        "        return yhat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ed6KZTlAZEyB"
      },
      "outputs": [],
      "source": [
        "model = LSTMRegressor(\n",
        "    input_dim=len(feature_cols),\n",
        "    hidden_dim=hidden_dim,\n",
        "    num_layers=num_layers,\n",
        "    dropout=dropout\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xnng9ePFZEyB"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l26_mjZHZEyB"
      },
      "outputs": [],
      "source": [
        "summary(model, input_size=(1, seq_len, len(feature_cols)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBOb6uVFZEyB"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gyU1jD2ZEyB"
      },
      "source": [
        "# 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kzHZcLoZEyB"
      },
      "outputs": [],
      "source": [
        "best_val = float(\"inf\")\n",
        "best_state = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDGzQky2ZEyB"
      },
      "outputs": [],
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    # train\n",
        "    model.train()\n",
        "    train_loss_sum, n_train_samples = 0.0, 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(xb)\n",
        "        loss = loss_fn(pred, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss_sum += loss.item() * xb.size(0)\n",
        "        n_train_samples += xb.size(0)\n",
        "    train_mse = train_loss_sum / n_train_samples\n",
        "\n",
        "    # val\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss_sum, n_val_samples = 0.0, 0\n",
        "        for xb, yb in val_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = loss_fn(pred, yb)\n",
        "            val_loss_sum += loss.item() * xb.size(0)\n",
        "            n_val_samples += xb.size(0)\n",
        "        val_mse = val_loss_sum / n_val_samples\n",
        "\n",
        "    if val_mse < best_val:\n",
        "        best_val = val_mse\n",
        "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "    print(f\"[{epoch:03d}] train_mse={train_mse:.5f}  val_mse={val_mse:.5f}\")\n",
        "\n",
        "# 베스트 가중치 복원\n",
        "if best_state is not None:\n",
        "    model.load_state_dict(best_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClruPwodZEyB"
      },
      "source": [
        "# 테스트 데이터 검증"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WY4R9WzGZEyB"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "preds_s, trues_s = [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device)\n",
        "        pred = model(xb).cpu().numpy()\n",
        "        preds_s.append(pred)\n",
        "        trues_s.append(yb.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxkSf76JZEyB"
      },
      "outputs": [],
      "source": [
        "preds_s = np.vstack(preds_s)\n",
        "trues_s = np.vstack(trues_s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swkn0NOYZEyB"
      },
      "outputs": [],
      "source": [
        "# 역변환(표준화 복원)\n",
        "preds = y_scaler.inverse_transform(preds_s)\n",
        "trues = y_scaler.inverse_transform(trues_s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nC3G23dZEyB"
      },
      "outputs": [],
      "source": [
        "# 앞부분 200개만 그려보기\n",
        "n_show = min(300, len(preds))\n",
        "plt.figure()\n",
        "plt.plot(trues[:n_show], label=\"True\")\n",
        "plt.plot(preds[:n_show], label=\"Pred\")\n",
        "plt.title(f\"Next-step forecasting of {target_col}\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYBxW92_ZEyB"
      },
      "source": [
        "# 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ONMzZZ4ZEyC"
      },
      "outputs": [],
      "source": [
        "# 신규데이터\n",
        "idx = -20\n",
        "df_part = test_df.iloc[idx-24:idx][feature_cols]\n",
        "part_next = df.iloc[idx+1][feature_cols]\n",
        "part_next"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75iIjvQcZEyC"
      },
      "outputs": [],
      "source": [
        "def predict(data):\n",
        "    data_tensor = torch.from_numpy(data).unsqueeze(0).to(device, dtype=torch.float32)\n",
        "    with torch.no_grad():\n",
        "        pred_next_s = model(data_tensor).cpu().numpy()\n",
        "    return y_scaler.inverse_transform(pred_next_s.reshape(-1, 1)).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IYulCqVZEyC"
      },
      "outputs": [],
      "source": [
        "predict(df_part.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qw0cTqdeZEyC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kU0vlScZEyC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UMcjGRYZEyC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrUi5hW5ZEyC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICsHCcrDZEyC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}