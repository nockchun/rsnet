{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4b593f0-64c7-4436-b203-23060904d7c9",
   "metadata": {},
   "source": [
    "# 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f9628b-269c-4ff2-ab69-55543bfa6153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dace4b-0ad2-4adb-9274-a047deaa5bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text: subject + \" \" + message를 공백으로 이어 붙여 만든 분류용 본문(제목과 본문을 합친 텍스트).\n",
    "ds = load_dataset(\"SetFit/enron_spam\")  # splits: 'train', 'test'\n",
    "print(ds)  # 구조 확인용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14517440-2c8f-480c-a3f4-7c32b608ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장 폴더 준비\n",
    "dir_store = Path(\"data/enron_spam\")\n",
    "dir_store.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5016a1c6-1fa3-4a91-bfdf-d928c0de6f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 스플릿을 CSV로 저장\n",
    "for split in ds.keys():  # 'train', 'test'\n",
    "    df = ds[split].to_pandas()\n",
    "    df.to_csv(dir_store / f\"enron_spam_{split}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c5eb91-d43d-484a-a47e-cf2b49534252",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saved to:\", list(dir_store.glob(\"*.csv\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be73956b-3b0b-4254-aca7-01294eb33450",
   "metadata": {},
   "source": [
    "# 기본 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da019c58-0db1-49eb-a79b-df922f60379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, random, math, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da6a85d-5e84-43f5-a9e5-56674c8c2665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 변수\n",
    "RANDOM_SEED = 42\n",
    "DATA_DIR = Path(\"data\")\n",
    "TRAIN_CSV = DATA_DIR / \"enron_spam/enron_spam_train.csv\"\n",
    "TEST_CSV  = DATA_DIR / \"enron_spam/enron_spam_test.csv\"\n",
    "OUT_DIR = DATA_DIR / \"eron_outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85def64a-8ea0-445a-9b8b-8977f179d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea090dbf-6e08-4440-8193-4ae28a6d4293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재현 가능성(reproducibility)을 위해 실험마다 동일한 난수를 쓰도록 고정값 설정\n",
    "torch.manual_seed(RANDOM_SEED) # PyTorch의 CPU 난수 시드(가중치 초기화, dropout 등 torch CPU 연산에서 쓰는 난수에 영향)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED) # 모든 GPU(CUDA 디바이스)의 난수 시드(드롭아웃, 일부 커널 내부 샘플링 등 CUDA 연산에 영향)\n",
    "np.random.seed(RANDOM_SEED) # NumPy 난수 시드(전처리/샘플링에 NumPy를 사용할 때 결과를 고정)\n",
    "random.seed(RANDOM_SEED) # Python 표준 random 모듈의 시드(데이터 셔플 등 random 모듈 사용 코드의 결과를 고정)\n",
    "# cuDNN이 비결정적(non-deterministic) 알고리즘을 쓰지 못하게 강제\n",
    "#  - 장점: 같은 입력과 시드로 항상 같은 출력(결정적 결과)\n",
    "#  - 단점: 일부 연산이 느려질 수 있음\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# 입력 크기별로 가장 빠른 알고리즘을 자동 탐색(benchmark)하는 기능 비활성화\n",
    "#  - 켜두면 실행마다 선택된 알고리즘이 달라져 결과가 흔들릴 수 있어 재현성 저하\n",
    "#  - 끄면 속도는 손해 볼 수 있지만 알고리즘 선택이 고정되어 재현성 향상\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e238ac39-1f4a-4671-8578-2f00f5ad6fda",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4540eb8a-0539-4f64-baa9-8cdb67904b13",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cee741-fde8-4e53-a36c-0f7ccecaf6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_test  = pd.read_csv(TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef47db7-2b6c-40b7-bae6-af1ade93599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc318ed4-08f7-4960-b0a8-32efe23339ed",
   "metadata": {},
   "source": [
    "## 결측 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb32db4-2975-4ad1-b40d-18e6e29587d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna(subset=[\"text\",\"label\"]).reset_index(drop=True)\n",
    "df_test = df_test.dropna(subset=[\"text\",\"label\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359f6e90-a50a-4ae1-a3b9-956e2d1f831d",
   "metadata": {},
   "source": [
    "## 추가 Feature 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f77e09-4bff-4cd8-84f4-4e9cf2cca115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 길이(문자수) & 라인수\n",
    "df_train[\"char_len\"] = df_train[\"text\"].str.len()\n",
    "df_train[\"line_cnt\"] = df_train[\"text\"].str.count(\"\\n\") + 1\n",
    "df_test[\"char_len\"] = df_test[\"text\"].str.len()\n",
    "df_test[\"line_cnt\"] = df_test[\"text\"].str.count(\"\\n\") + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872534c5-b1b4-4df9-991f-41dee17217d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c9c481-9cd5-4003-8512-80733303f6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단 Subject 추출 (본문 맨 처음 줄이 'Subject:' 패턴인 경우)\n",
    "def extract_subject(s):\n",
    "    if not isinstance(s, str):\n",
    "        return None\n",
    "    m = re.match(r\"(?i)^subject:\\s*(.*)\", s.splitlines()[0]) if s else None\n",
    "    return m.group(1).strip() if m else s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1f2107-65f5-4c3d-963c-03a514920965",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"subject\"] = df_train[\"text\"].apply(extract_subject)\n",
    "df_test[\"subject\"] = df_test[\"text\"].apply(extract_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e815c172-a871-4343-b3bc-e6407b7c130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea59535d-8c4a-43d2-a6d7-9acf3a07da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"label\"].value_counts(normalize=True) # 빈도수 대신 비율(각 값의 등장 횟수 ÷ 전체 개수)을 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c57d58-2128-490e-a8f8-246de7519487",
   "metadata": {},
   "source": [
    "# 길이(문자수) 분포 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c5bb51-8f3d-4b1c-9e91-78b5192397a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74688536-4e50-490b-8070-a67ccbaf4dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\", rc={\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.spines.right\": False,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6472adf2-6226-4824-92c8-f82e94849776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCharLengthDistribution(df, col=\"char_len\", up_bound=20_000):\n",
    "    data = df[col].clip(upper=up_bound)\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    ax = sns.histplot(data=data, bins=50, stat=\"percent\")\n",
    "\n",
    "    median = data.median()\n",
    "    mean = data.mean()\n",
    "    q95 = data.quantile(0.95)\n",
    "    ax.axvline(median, ls=\"--\", lw=1, color=\"red\", label=f\"median = {median:.0f}\")\n",
    "    ax.axvline(mean,   ls=\":\",  lw=1, color=\"red\", label=f\"mean = {mean:.0f}\")\n",
    "    ax.axvline(q95,    ls=\"-.\", lw=1, color=\"red\", label=f\"quantile 95 = {q95:.0f}\")\n",
    "\n",
    "    ax.set_title(\"Character length distribution (train)\", pad=10)\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel(\"percent\")\n",
    "    ax.legend(loc=\"upper right\", frameon=False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15745b0f-d9c9-4bc5-acfc-fd2962b55faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCharLengthDistribution(df_train, \"char_len\", 20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100172a0-c853-49a0-bc39-270f9c8a872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCharLengthDistribution(df_test, \"char_len\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fe5cc3-316d-4079-8b2d-4e2a0eb33e4c",
   "metadata": {},
   "source": [
    "# 토크나이징 (글자 -> 숫자)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4484b46d-e736-4636-b48d-0b830d57f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0357f0-7951-4363-92f3-a109b102fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPM_DIR = OUT_DIR / \"tokenizer\"\n",
    "SPM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SPM_PREFIX = str(SPM_DIR / \"enron_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f1cd29-cb81-47cb-8b4f-176066d2bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_input_path = SPM_DIR / \"spm_input_train.txt\"\n",
    "df_train[\"text\"].to_csv(sp_input_path, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06840b1-73d8-423c-97e9-63ef720c5d51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.Train(\n",
    "    input=str(sp_input_path),\n",
    "    model_prefix=SPM_PREFIX,\n",
    "    vocab_size=5000,\n",
    "    model_type=\"unigram\",              # 또는 \"bpe\"\n",
    "    character_coverage=0.9995,         # 영문 위주라 0.9995, 멀티언어면 1.0 권장\n",
    "    user_defined_symbols=[\"<|PAD|>\"],\n",
    "    # input_sentence_size=200000,        # 대용량일 경우 샘플링\n",
    "    shuffle_input_sentence=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c88e89-b7f2-468d-982e-b147b3b7e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_sp = spm.SentencePieceProcessor()\n",
    "tokenizer_sp.load(SPM_PREFIX + \".model\")\n",
    "print(\"SentencePiece vocab size:\", tokenizer_sp.get_piece_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dec9d76-e3b1-495e-9a7b-50c9736695f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_pieces(text):\n",
    "    return tokenizer_sp.encode_as_pieces(text) if isinstance(text, str) else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a8c9f6-48f1-4088-8d95-3749adbaa394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"tok_len\"] = df_train[\"text\"].apply(lambda x: len(sp_pieces(x)))\n",
    "df_test[\"tok_len\"]  = df_test[\"text\"].apply(lambda x: len(sp_pieces(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c442d7-2489-420d-b93f-6f6055f08490",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead5969e-f55a-4313-a14d-093d2633b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCharLengthDistribution(df_train, \"tok_len\", 4_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a048e-7659-4731-a826-e82a9bc9fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_for_freq = df_train.sample(n=min(5000, len(df_train)), random_state=RANDOM_SEED)\n",
    "cnt = Counter(tok for txt in sample_for_freq[\"text\"] for tok in sp_pieces(txt))\n",
    "top20 = cnt.most_common(50)\n",
    "print(\"Top 20 tokens:\", top20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0472d8b6-6335-4927-b3f6-6ff857313169",
   "metadata": {},
   "source": [
    "# 머신러닝 베이스라인 (SentencePiece → TF-IDF → 로지스틱/선형 SVM/나이브베이즈)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3e1fe8-28c0-4497-9e3e-3ffaa4767715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517b37ca-557d-43ef-8a56-03369b91052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train을 다시 train/val 분리 (모델 선택용)\n",
    "train_texts = df_train[\"text\"].tolist()\n",
    "train_labels = df_train[\"label\"].astype(int).tolist()\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    train_texts, train_labels, test_size=0.1, random_state=RANDOM_SEED, stratify=train_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b505731-1a5d-4206-b250-ee418b2a2e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통 TF-IDF (unigram+bigram 권장, 필요시 조정)\n",
    "# (1,2)나 (1,3)처럼 늘리면 **연속 토큰 패턴(콜로케이션)**을 잡아내 표현력이 증가합니다.\n",
    "# SentencePiece처럼 서브워드 토큰을 쓸 때는, 바이그램이 실제 “단어” 수준 조합을 어느 정도 복원해 주는 효과가 있어 도움이 되는 경우가 많습니다.\n",
    "tfidf = TfidfVectorizer(\n",
    "    tokenizer=sp_pieces,\n",
    "    lowercase=False,    # SentencePiece는 케이스 정보 유지해도 OK\n",
    "    ngram_range=(1, 2), # 몇 개의 연속 토큰을 하나의 특징으로 만들지를 정하는 파라미터: uni+bi\n",
    "    min_df=2,           # document frequency(문서 빈도) 하한선. “최소 몇 개 문서에서 등장한 토큰만 어휘(vocabulary)에 남길 것인가”를 정함.\n",
    "    max_features=5000,  # 단어(특징) 사전의 최대 크기를 제한. 말뭉치 전체에서 등장 빈도(term frequency)가 높은 순으로 정렬해 상위 max_features개만 어휘에 남깁\n",
    "    preprocessor=None,\n",
    "    token_pattern=None,     # custom tokenizer 사용시 None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3261d2-a21d-4e88-b90b-4ac324e2aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = tfidf.fit_transform(X_tr)\n",
    "Xva = tfidf.transform(X_val)\n",
    "Xte = tfidf.transform(df_test[\"text\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0540b9b0-2c47-4c4e-b0ee-7074de2dba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr.shape, len(y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79bf634-0e3a-4b10-8ffc-da434ad94b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTfidfInfo(idx=0):\n",
    "    i = 2  # 1번째 샘플 (Python은 0부터 시작)\n",
    "    row = Xtr[i]            # shape: (1, vocab_size) 인 CSR 행렬\n",
    "\n",
    "    # 어휘(특징) 이름\n",
    "    feat_names = np.array(tfidf.get_feature_names_out())\n",
    "\n",
    "    print(\"=== Xtr[0] 기본 정보 ===\")\n",
    "    print(\"type:\", type(row))\n",
    "    print(\"shape:\", row.shape)\n",
    "    print(\"nnz(해당 희소 행에서 0이 아닌 원소의 개수):\", row.nnz)\n",
    "\n",
    "    # 이 문서에서 등장한(가중치>0) 특징들과 가중치\n",
    "    idx = row.indices       # 비영零 항목의 열 인덱스들\n",
    "    val = row.data          # 해당 TF-IDF 값들\n",
    "\n",
    "    # 가중치 내림차순 상위 20개 토큰만 보기\n",
    "    order = np.argsort(-val)\n",
    "    topk = order[:20]\n",
    "\n",
    "    print(\"\\n=== Xtr[0] Top-20 특징(토큰/바이그램) by TF-IDF ===\")\n",
    "    for j in topk:\n",
    "        print(f\"{feat_names[idx[j]]:30s} {val[j]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e157edc-ff94-450c-8b10-299ba8725e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "printTfidfInfo(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342153d9-cf75-445a-a8b6-71140b68a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-3) 세 가지 분류기 학습 & 검증\n",
    "models = {\n",
    "    \"logreg\": LogisticRegression(max_iter=2000, n_jobs=1),\n",
    "    \"linear_svm\": LinearSVC(),\n",
    "    \"mnb\": MultinomialNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861dcd35-d42a-4b11-ad3d-4d54b22a3a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores = {}\n",
    "for name, clf in models.items():\n",
    "    clf.fit(Xtr, y_tr)\n",
    "    pred_val = clf.predict(Xva)\n",
    "    acc = accuracy_score(y_val, pred_val)\n",
    "    val_scores[name] = acc\n",
    "    print(f\"[VAL] {name}: acc={acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a8422-9adb-48c4-979f-09913e41d865",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_name = max(val_scores, key=val_scores.get)\n",
    "best_model = models[best_name]\n",
    "print(\"Best on val:\", best_name, val_scores[best_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffcd947-f4a9-45ae-980d-319b7224af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-4) 테스트 평가\n",
    "pred_test = best_model.predict(Xte)\n",
    "print(classification_report(df_test[\"label\"].astype(int).tolist(), pred_test, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0830423e-7187-42c3-ba1a-51f2f581fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-5) 혼동행렬 저장\n",
    "cm = confusion_matrix(df_test[\"label\"].astype(int).tolist(), pred_test)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e1cb2f-ae1a-40ca-b114-ba1d1c56ae2b",
   "metadata": {},
   "source": [
    "# Step 4. 딥러닝 베이스라인 (SentencePiece ID → TextCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a22367a-d7f5-40d8-8b9d-d3c2b869eab2",
   "metadata": {},
   "source": [
    "## 환경 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9102b768-047d-4c60-8136-35f852b4ffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b4742-5b8c-4e02-8a94-be3f3cfdc159",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafda49b-fbea-4a1f-8391-bfc8b5ca0055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-1) 하이퍼파라미터\n",
    "VOCAB_SIZE = tokenizer_sp.get_piece_size()\n",
    "PAD_ID = tokenizer_sp.piece_to_id(\"<|PAD|>\") # 우리가 user_defined_symbols로 추가\n",
    "UNK_ID = tokenizer_sp.unk_id()\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 64\n",
    "EMBED_DIM = 128\n",
    "FILTERS = 128\n",
    "KERNEL_SIZES = [3,4,5]\n",
    "DROPOUT = 0.2\n",
    "EPOCHS = 20\n",
    "LR = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a86eade-8526-430e-a854-13f4c0d63fcd",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52bbed0-902e-4f51-83bd-baee521984ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-2) 토큰화/패딩\n",
    "def encode_ids(text, max_len=MAX_LEN):\n",
    "    ids = tokenizer_sp.encode_as_ids(text)[:max_len]\n",
    "    if len(ids) < max_len:\n",
    "        ids = ids + [PAD_ID] * (max_len - len(ids))\n",
    "    return np.array(ids, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a05238-9178-41b2-a81c-a7086dab9cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnronDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x = encode_ids(self.texts[i])\n",
    "        y = int(self.labels[i])\n",
    "        return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f462e06-69e7-45bc-9d9d-60137b47eeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-3) split (train/val은 앞서 만든 걸 재사용)\n",
    "train_ds = EnronDataset(X_tr, y_tr)\n",
    "val_ds   = EnronDataset(X_val, y_val)\n",
    "test_ds  = EnronDataset(df_test[\"text\"].tolist(), df_test[\"label\"].astype(int).tolist())\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eec60b-163d-4148-9ca6-e5eaf298abaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cec134-ed56-413b-9f7f-8840126d9b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23662c82-9b1b-4215-b147-3adce0246625",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e013aaf-684a-4eb2-946b-ad259431de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextCNN: 여러 크기의 1D 콘볼루션으로 n-그램 특징을 뽑고,\n",
    "# 각 필터의 \"시간 차원\"에 대해 글로벌 맥스 풀링 후 모두 이어 붙여 분류하는 모델\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,            # 전체 단어 수 (임베딩 테이블의 행 수)\n",
    "        embed_dim,             # 임베딩 차원 수 (E)\n",
    "        num_classes=2,         # 분류할 클래스 개수\n",
    "        kernel_sizes=[3, 4, 5],# 사용할 1D 커널(필터) 길이들: 3-그램, 4-그램, 5-그램\n",
    "        num_filters=128,       # 각 커널 크기마다 뽑을 채널(필터) 수 (C)\n",
    "        dropout=0.5,           # 드롭아웃 비율\n",
    "        pad_idx=0              # 패딩 토큰의 인덱스 (이 행은 학습 중 업데이트되지 않음)\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # (vocab_size, embed_dim) 크기의 임베딩 테이블. 입력 x는 torch.long이어야 함.\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # Conv1d(in_channels=E, out_channels=C, kernel_size=k)\n",
    "        # Conv1d는 입력을 (B, 채널, 길이)로 받기 때문에 forward에서 transpose로 바꿉니다.\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=embed_dim, out_channels=num_filters, kernel_size=k)\n",
    "            for k in kernel_sizes\n",
    "        ])\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # 최종 특징 벡터 크기: (C * 커널크기개수). 여기에 선형층으로 클래스 로짓 출력.\n",
    "        self.fc = nn.Linear(num_filters * len(kernel_sizes), num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, L)  — 배치 크기 B, 문장 길이 L (각 토큰은 정수 인덱스)\n",
    "        emb = self.embedding(x)                # (B, L, E) — 토큰을 임베딩 벡터로 변환\n",
    "        emb = emb.transpose(1, 2)              # (B, E, L) — Conv1d가 기대하는 형태(채널=E)\n",
    "\n",
    "        # 각 커널 크기별로: Conv1d -> ReLU\n",
    "        # conv(emb): (B, C, L-k+1)\n",
    "        conv_outs = [torch.relu(conv(emb)) for conv in self.convs]\n",
    "\n",
    "        # \"시간(시퀀스) 차원\"에 대해 글로벌 맥스 풀링:\n",
    "        # dim=2가 길이 축이므로 결과는 (B, C)\n",
    "        pooled = [torch.max(co, dim=2).values for co in conv_outs]  # .values만 사용\n",
    "\n",
    "        # 여기서 커널별 (B, C) 특징들을 피처 차원(dim=1)으로 이어붙여 (B, C * len(K))로 만듭니다.\n",
    "        cat = torch.cat(pooled, dim=1)         # 여러 텐서를 지정한 축으로 이어붙여(concatenate) 하나의 텐서로 만듬\n",
    "                                               # 예: 커널 3개라면 (B, 3*C)\n",
    "\n",
    "        cat = self.dropout(cat)                # (B, C * len(K))에 드롭아웃\n",
    "\n",
    "        return self.fc(cat)                    # (B, num_classes) — 클래스별 로짓\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba80979-56e4-4993-8c08-e99237e5964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextCNN(\n",
    "    VOCAB_SIZE, EMBED_DIM,\n",
    "    num_classes=2, kernel_sizes=KERNEL_SIZES, num_filters=FILTERS, dropout=DROPOUT, pad_idx=PAD_ID\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9be613-e611-4bd6-940a-6926873a7eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a215dcc-6d50-4a20-bbcf-6ab5eb52c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe25dbf-55da-41ed-9e80-232b25288667",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c51a41-4215-495d-b41c-1745126a709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc621b0-c557-42f9-9691-a4bd10006ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    all_y, all_p = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            all_y.extend(yb.cpu().numpy().tolist())\n",
    "            all_p.extend(preds.cpu().numpy().tolist())\n",
    "    acc = accuracy_score(all_y, all_p)\n",
    "    f1  = f1_score(all_y, all_p)\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f9840-82a9-4238-9e75-c9040a78a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val = -1\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    train_loss = total_loss / len(train_loader.dataset)\n",
    "    val_acc, val_f1 = evaluate(val_loader)\n",
    "    print(f\"Epoch {epoch}: train_loss={train_loss:.4f}  val_acc={val_acc:.4f}  val_f1={val_f1:.4f}\")\n",
    "    # 간단한 early-best 저장\n",
    "    if val_f1 > best_val:\n",
    "        best_val = val_f1\n",
    "        torch.save(model.state_dict(), OUT_DIR/\"textcnn_best.pt\")\n",
    "        print(\"  (saved best)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99795ef1-447c-4011-9ccb-1d3d6cbbe7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-6) 테스트 평가\n",
    "model.load_state_dict(torch.load(OUT_DIR/\"textcnn_best.pt\", map_location=device))\n",
    "test_acc, test_f1 = evaluate(test_loader)\n",
    "print(f\"[TEST] TextCNN acc={test_acc:.4f}  f1={test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba8f294-b937-4099-9311-31e9e5f7738b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d734f-fbd0-4b6d-8fc0-9d743b053d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd919c88-3e9a-49d0-b11a-ebc700b8e395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0c0ebe-5f3d-49ed-be84-171095a932ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
