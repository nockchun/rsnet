{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d52d5a7-bd04-43be-93dd-4a392255cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset # Using TensorDataset for simple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e33842-eb66-4240-a44d-70f7a6bd4eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e546ce-74d6-43dd-aac7-8ac5faaece55",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770bceb5-b3fa-400b-8e8f-aaec8e981ce9",
   "metadata": {},
   "source": [
    "# Simulate Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37467898-a24b-4cf0-8a67-d0b6bb232636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input\n",
    "inp = torch.tensor([0.5, -1.0]).to(device)\n",
    "inp.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7773d190-4c08-46dd-935a-15a71278de93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make neural network\n",
    "neural1 = nn.Linear(2, 1).to(device)\n",
    "print(neural1.weight.data.cpu().numpy())\n",
    "print(neural1.bias.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c5840d-7888-49e8-9c40-d6a74cab2a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted sum\n",
    "wx_b = neural1(inp)\n",
    "wx_b.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73a9ac4-4784-4757-b114-a02bf338313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function\n",
    "out = torch.sigmoid(wx_b)\n",
    "out.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faa4b0d-75a6-4890-9f23-aeaaa675980f",
   "metadata": {},
   "source": [
    "# Multi-Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e2680-3b53-4266-92e2-f4f1b084da72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make neural network\n",
    "neural1 = nn.Linear(2, 3).to(device)\n",
    "print(neural1.weight.data.cpu().numpy())\n",
    "print(neural1.bias.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5950fb2c-8a28-448b-a6b7-cedf0217ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural2 = nn.Linear(3, 1).to(device)\n",
    "print(neural2.weight.data.cpu().numpy())\n",
    "print(neural2.bias.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff998bc3-f6db-4666-bd34-ade359b911de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted sum\n",
    "wx_b1 = neural1(inp)\n",
    "wx_b2 = neural2(wx_b1)\n",
    "print(wx_b1.data.cpu().numpy())\n",
    "print(wx_b2.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b49c0ef-55fc-453c-ba05-9e4c9e414932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function\n",
    "out = torch.sigmoid(wx_b2)\n",
    "out.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36d372d-9e6d-43ec-a335-d215c73072ce",
   "metadata": {},
   "source": [
    "# Activation Functions\n",
    "- 비선형이 없으면 아무리 깊어도 전체가 하나의 선형변환과 같음.\n",
    "- 비선형이 들어가야 XOR 같은 비선형 패턴·복잡한 결정 경계를 학습할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90366bd-8cf3-403f-81e6-d9291ad861e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = torch.linspace(-6, 6, 100) # Input values for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ac8db9-3acf-43e3-b13a-027523aeca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals.numpy().round(2), len(x_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f631778-802d-4de9-baf6-f1e2d3a6a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid\n",
    "sigmoid_fn = nn.Sigmoid()\n",
    "y_sigmoid = sigmoid_fn(x_vals)\n",
    "y_sigmoid.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a8266-a4fb-4798-8101-808fc51d22b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tanh\n",
    "tanh_fn = nn.Tanh()\n",
    "y_tanh = tanh_fn(x_vals)\n",
    "y_tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c13b92-5b71-420d-9fc4-5283ba144599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU\n",
    "relu_fn = nn.ReLU()\n",
    "y_relu = relu_fn(x_vals)\n",
    "y_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a8e17b-c451-4dae-8fda-1d4ef916b81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaky ReLU\n",
    "leaky_relu_fn = nn.LeakyReLU(negative_slope=0.1)\n",
    "y_leaky_relu = leaky_relu_fn(x_vals)\n",
    "y_leaky_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f341d170-fc84-46ed-9e56-db0ef10cb63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax (applied to a sample batch of logits)\n",
    "softmax_fn = nn.Softmax(dim=1)\n",
    "sample_logits = torch.tensor([[1.0, -0.5, 2.0], [0.1, 0.5, 0.2]]) # Batch of 2, 3 classes\n",
    "y_softmax = softmax_fn(sample_logits)\n",
    "print(y_softmax)\n",
    "print(y_softmax[0,:].sum())\n",
    "print(y_softmax[1,:].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188e8a73-8f59-4ea3-b4ff-2c7438866332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(x_vals.numpy(), y_sigmoid.numpy(), label='Sigmoid')\n",
    "plt.title('Sigmoid: 1 / (1 + exp(-x))')\n",
    "plt.xlabel('x'); plt.ylabel('f(x)'); plt.grid(True); plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(x_vals.numpy(), y_tanh.numpy(), label='Tanh')\n",
    "plt.title('Tanh: (exp(x) - exp(-x)) / (exp(x) + exp(-x))')\n",
    "plt.xlabel('x'); plt.ylabel('f(x)'); plt.grid(True); plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(x_vals.numpy(), y_relu.numpy(), label='ReLU')\n",
    "plt.title('ReLU: max(0, x)')\n",
    "plt.xlabel('x'); plt.ylabel('f(x)'); plt.grid(True); plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(x_vals.numpy(), y_leaky_relu.numpy(), label='Leaky ReLU (slope=0.1)')\n",
    "plt.title('Leaky ReLU: max(0.1*x, x)')\n",
    "plt.xlabel('x'); plt.ylabel('f(x)'); plt.grid(True); plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc382b4-5364-4942-85ef-ba2023aca2c6",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptrons (MLP) - Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda4e2e7-f9c1-4719-995f-616d479f0872",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        # nn.Module을 초기화 (파이토치의 모든 모델은 이걸 상속)\n",
    "        super(SimpleMLP, self).__init__()\n",
    "\n",
    "        # 완전연결(선형) 층 1: 입력 특징(input_size) -> 은닉 특징(hidden_size)\n",
    "        # 예) 784(28x28 이미지) -> 128\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        # ReLU 활성화: 음수는 0으로, 양수는 그대로 통과 (학습을 돕는 비선형 함수)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # 완전연결 층 2: hidden_size -> hidden_size\n",
    "        # (두 번째 은닉층, 차원을 그대로 유지하는 설정)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        # 두 번째 ReLU\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # 출력층: hidden_size -> num_classes\n",
    "        # 분류 문제라면 클래스 수만큼 로짓(logits)을 뽑아냄\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: 입력 텐서, 모양은 [batch_size, input_size]\n",
    "        # 예) 배치 크기 32, 입력 784라면 [32, 784]\n",
    "\n",
    "        out = self.fc1(x)     # [batch_size, hidden_size]\n",
    "        out = self.relu1(out) # 비선형 통과\n",
    "\n",
    "        out = self.fc2(out)   # [batch_size, hidden_size]\n",
    "        out = self.relu2(out) # 비선형 통과\n",
    "\n",
    "        out = self.fc3(out)   # [batch_size, num_classes] (각 클래스의 점수=로짓)\n",
    "        \n",
    "        return out            # 주의: 보통 분류 손실(CrossEntropyLoss)은 softmax 없이 '로짓'을 그대로 받습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f81fa7-d2df-4181-8fd9-a21e4511fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 100  # 입력 특성(피처) 차원\n",
    "hidden_dim = 64  # 은닉층 차원\n",
    "output_dim = 5   # 분류할 클래스 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0075325-bebc-4c20-b0ed-5f845504695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMLP(input_dim, hidden_dim, output_dim).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61210d5-ee45-41f6-8fb9-313d2bf2803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ab99e1-5441-4aef-bc35-a47cb4c86510",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "dummy_input = torch.randn(batch_size, input_dim).to(device) # [batch_size, input_features]\n",
    "dummy_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b99519-b41b-46de-b9ef-17bc639de163",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): # 예측시 기울기(gradient) 계산이 필요 없습니다\n",
    "    predictions = model(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9818d5e4-b938-4a81-9b3b-7fdc5be217ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.shape)\n",
    "print(predictions[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195f547c-6a5d-41a0-93e4-6c6e666ea10e",
   "metadata": {},
   "source": [
    "# Loss Functions\n",
    "- 학습을 하기 위해 모델의 error를 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d935b640-a8c5-413f-bc86-7bf77483ab20",
   "metadata": {},
   "source": [
    "## Mean Squard Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa7007-120f-475b-8f08-a941b2e7a422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Regression\n",
    "loss_mse_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60818a08-2d4b-4fdc-87a0-b1ef1db7da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_reg = torch.tensor([1.0, 2.5, 3.8], device=device) # 모델을 히용하여 Forward 연산을 한 결과 outputs\n",
    "targets_reg = torch.tensor([1.2, 2.3, 4.0], device=device)     # 학습을 위해 입력으로 넣어준 Label. 즉 정답."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d6d2d-6374-4f48-9bdd-09661e791c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = loss_mse_fn(predictions_reg, targets_reg)\n",
    "mse.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1d7932-bf4d-4a4b-85fc-67c273244f0e",
   "metadata": {},
   "source": [
    "## Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd1d62b-dbf5-4cd7-8ddc-fa5446751fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Multi-class Classification\n",
    "loss_ce_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47a2703-3c8d-4813-890d-44a5c3220a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mc = torch.tensor([[2.0, 0.5, -1.0], [0.1, 1.5, 0.2]], device=device) # 2 samples, 3 classes\n",
    "targets_mc = torch.tensor([0, 1], device=device) # True class indices for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f67f89-d9ef-42fc-a14a-2047642c603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = loss_ce_fn(predictions_mc, targets_mc)\n",
    "ce.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfcebaf-bfcc-4cfb-b9cd-6bf031c7b267",
   "metadata": {},
   "source": [
    "# Binary Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b845a5f9-d1d8-4fae-928d-a8117adda307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Binary Classification\n",
    "loss_bce_logits_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6474423a-d7b1-4cfd-9afc-d0b09771c331",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_bc = torch.tensor([-0.5, 1.5, -2.0, 3.0], device=device).unsqueeze(1) # 4 samples, 1 logit each\n",
    "targets_bc = torch.tensor([0.0, 1.0, 0.0, 1.0], device=device).unsqueeze(1)       # True binary labels (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f6bb6-959f-4422-85f1-caacf1c82edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_wl = loss_bce_logits_fn(predictions_bc, targets_bc)\n",
    "bce_wl.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdd137f-e4c0-4185-9a46-b4fd394d2989",
   "metadata": {},
   "source": [
    "# Optimizers\n",
    "- 학습하는 방법 : 모델 파라미터(W:weight, B:bias)를 학습. loss function 값이 최소화 도로록 만듬."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d674f0-a94f-4a98-8e27-4de3f8c32832",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63eddfd-44fa-455d-9566-77f28677a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy input, target\n",
    "dummy_input = torch.randn(5, 10).to(device)\n",
    "dummy_target = torch.randn(5, 2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e7f4ab-e902-45e8-ba5e-65ecf545e7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input.shape, dummy_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402efea2-0c84-4bb0-a9f9-c6941ed32cbc",
   "metadata": {},
   "source": [
    "## Creaate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef5c004-8e9c-418d-82bc-a9ce90e45161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy model for optimizer demonstration\n",
    "dummy_model = nn.Linear(10, 2).to(device) # 10 input features, 2 output features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a753d40a-de82-4a50-8911-d5d634b01f0f",
   "metadata": {},
   "source": [
    "## Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bb99fc-04e5-456b-af94-93ab28ee7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b64edc-e277-484b-b94f-7c1292a4ee7b",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096bda4-4371-448a-88e4-fa2c1b3352a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam Optimizer\n",
    "optimizer = optim.Adam(dummy_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164e0110-8541-4f45-b4ba-a209012ddcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332471b7-9743-4967-bdc0-add23d848049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD Example Step\n",
    "optimizer.zero_grad()                     # Clear previous gradients\n",
    "outputs = dummy_model(dummy_input)        # Forward pass\n",
    "loss = loss_fn(outputs, dummy_target) # Calculate loss\n",
    "loss.backward()                           # Backward pass (compute gradients)\n",
    "optimizer.step()                          # Update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03af6c9-ee49-4141-9c23-bef0f4d492cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7efeae-d2ed-4c83-b32f-aabf6f42e474",
   "metadata": {},
   "source": [
    "# Neural Network For XOR Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046594e-2373-4167-bcdc-85ec6b87a6b3",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b703ff-a47e-45b3-b08e-04761d2ed478",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_xor = torch.tensor([[0., 0.], [0., 1.], [1., 0.], [1., 1.]], device=device)\n",
    "y_xor = torch.tensor([[0.], [1.], [1.], [0.]], device=device)\n",
    "X_xor.shape, y_xor.shape, X_xor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9c0f84-92e1-4c39-9d74-2e2c24d5e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple Dataset\n",
    "xor_dataset = TensorDataset(X_xor, y_xor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc94c3-cd4e-4bc6-86f9-9275c00a960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple DataLoader\n",
    "xor_dataloader = DataLoader(xor_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a897bc-0da0-48bf-989f-b126290fa9fb",
   "metadata": {},
   "source": [
    "## Define The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bada5443-6e04-4068-b25b-bbabf1bfec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XORNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XORNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 8)      # 2 input features, 8 neurons in hidden layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(8, 1)      # 8 hidden neurons, 1 output neuron\n",
    "        # Sigmoid will be applied implicitly by BCEWithLogitsLoss or explicitly after if using BCELoss\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x # Output raw logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23fc4a7-db4f-4eb0-839a-a48b2e68fe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_model = XORNet().to(device)\n",
    "xor_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b6403b-70b0-4a37-a7bc-1711e4f02231",
   "metadata": {},
   "source": [
    "## Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9064008-6e18-411e-8688-4232810d4808",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss() # Handles sigmoid internally, more stable\n",
    "optimizer = optim.Adam(xor_model.parameters(), lr=0.05) # Adam with a slightly higher LR for faster convergence on XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da64816-8cde-487c-a75a-326450b21415",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90baeb-23bb-4a67-9ab7-493719363ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8321f9bc-3421-4f49-a095-9a1c3fec64ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_history = []\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in xor_dataloader: # Dataloader handles batching\n",
    "        # Inputs and labels are already on `device` if X_xor, y_xor were created on device\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = xor_model(inputs) # Model outputs raw logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    losses_history.append(loss.item())\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93e8bbf-e550-4217-a748-c3d0366993ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses_history)\n",
    "plt.title('Training Loss for XOR Problem')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('BCEWithLogitsLoss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcfca8d-ec9d-4414-bd46-dadbe7070395",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "- logits는 모델이 계산한 정규화 전 점수(원시 점수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d650d232-fc58-47b0-a643-1180a44bed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_model.eval() # Set model to evaluation mode (important for layers like dropout, batchnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d084b009-a7fa-4326-9d01-da7dd795209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictXOR(data=[1, 0]):\n",
    "    tensor_data = torch.tensor([data], dtype=torch.float32, device=device)\n",
    "    \n",
    "    with torch.no_grad(): # Disable gradient calculations for inference\n",
    "        test_predictions_logits = xor_model(tensor_data)\n",
    "        test_predictions_probs = torch.sigmoid(test_predictions_logits)\n",
    "\n",
    "    return int((test_predictions_probs >= 0.5).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20e1202-cbb9-4aec-8e1f-60e93e997f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictXOR([1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb203a-2037-489e-b738-9b74f8622cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cfcc35-73fd-46f8-938f-643167e227ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d6d26-d09f-4cc7-bae4-92071b8472d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c409d1ff-31d9-4c7c-8f9c-734160036ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
