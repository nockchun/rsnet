{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "approved-piano",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b><center>Sequential & Functional API Model</center></b>\n",
    "    <b><center>Based On TensorFlow Documents</center></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-compromise",
   "metadata": {},
   "source": [
    "# Configure Learning Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "optimum-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/nockchun/rspy --force\n",
    "# !pip install mybatis_mapper2sql\n",
    "import rspy as rsp\n",
    "rsp.setSystemWarning(off=True)\n",
    "rsp.fixMemoryProblem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beginning-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bacterial-operator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(linewidth=200, precision=2)\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-toddler",
   "metadata": {},
   "source": [
    "# Neuron by Dense\n",
    "Generally, all layers in Keras need to know the shape of their inputs in order to be able to create their weights. So when you create a layer like this, initially, it has no weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "polish-lighting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = layers.Dense(3)\n",
    "layer.weights  # Empty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-fruit",
   "metadata": {},
   "source": [
    "It creates its weights the first time it is called on an input, since the shape of the weights depends on the shape of the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "superb-meaning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_3/kernel:0' shape=(4, 3) dtype=float32, numpy=\n",
       " array([[ 0.76,  0.07, -0.82],\n",
       "        [ 0.72, -0.6 ,  0.86],\n",
       "        [-0.03, -0.32,  0.26],\n",
       "        [-0.61,  0.28, -0.33]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call layer on a test input\n",
    "x = tf.ones((1, 4))\n",
    "y = layer(x)\n",
    "layer.weights  # Now it has weights, of shape (4, 3) and (3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-halifax",
   "metadata": {},
   "source": [
    "# Creating a Sequential model\n",
    "You can create a Sequential model by passing a list of layers to the Sequential constructor:\n",
    "\n",
    "Also note that the Sequential constructor accepts a name argument, just like any layer or model in Keras. This is useful to annotate TensorBoard graphs with semantically meaningful names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fresh-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation=\"relu\", name=\"dense_01\"),\n",
    "        layers.Dense(3, activation=\"relu\", name=\"dense_02\"),\n",
    "        layers.Dense(4, name=\"output\"),\n",
    "    ], name=\"seq_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-moderator",
   "metadata": {},
   "source": [
    "It's layers are accessible via the layers attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tracked-bridal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_01\n",
      "dense_02\n",
      "output\n"
     ]
    }
   ],
   "source": [
    "for item in model.layers:\n",
    "    print(item.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-stranger",
   "metadata": {},
   "source": [
    "You can also create a Sequential model incrementally via the add() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dimensional-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(2, activation=\"relu\"))\n",
    "model.add(layers.Dense(3, activation=\"relu\"))\n",
    "model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-cornell",
   "metadata": {},
   "source": [
    "Note that there's also a corresponding pop() method to remove layers: a Sequential model behaves very much like a list of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "imposed-apollo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x7f320d761850>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f320d761400>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pop()\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-tonight",
   "metadata": {},
   "source": [
    "Schematically, the above Sequential model is equivalent to this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aware-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 layers\n",
    "layer1 = layers.Dense(2, activation=\"relu\", name=\"layer1\")\n",
    "layer2 = layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
    "layer3 = layers.Dense(4, name=\"layer3\")\n",
    "\n",
    "# Call layers on a test input\n",
    "x = tf.ones((3, 3))\n",
    "y = layer3(layer2(layer1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-austria",
   "metadata": {},
   "source": [
    "Naturally, weights of dense also applies to Sequential models. When you instantiate a Sequential model without an input shape, it isn't \"built\": it has no weights (and calling model.weights results in an error stating just this). The weights are created when the model first sees some input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "irish-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation=\"relu\"),\n",
    "        layers.Dense(3, activation=\"relu\"),\n",
    "        layers.Dense(4),\n",
    "    ]\n",
    ")  # No weights at this stage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "charming-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, you can't do this:\n",
    "# model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pleased-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You also can't do this:\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "neither-metabolism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of weights after calling the model: 6\n"
     ]
    }
   ],
   "source": [
    "# Call the model on a test input\n",
    "x = tf.ones((1, 4))\n",
    "y = model(x)\n",
    "print(\"Number of weights after calling the model:\", len(model.weights))  # 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "involved-helping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              multiple                  10        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  9         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  16        \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-acceptance",
   "metadata": {},
   "source": [
    "18*18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-geneva",
   "metadata": {},
   "source": [
    "# Input\n",
    "you should start your model by passing an Input object to your model, so that it knows its input shape from the start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "alert-difference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Input(shape=(4,)))\n",
    "model.add(layers.Dense(2, activation=\"relu\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-watson",
   "metadata": {},
   "source": [
    "Note that the Input object is not displayed as part of model.layers, since it isn't a layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "furnished-sleep",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x7f31ec131400>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "isolated-measurement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A simple alternative is to just pass an input_shape argument to your first layer:\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(2, activation=\"relu\", input_shape=(4,)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "executive-macro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(2, input_shape=(4,)))\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "possible-avenue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x7f31ec12d1c0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f31ec0f7dc0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-adjustment",
   "metadata": {},
   "source": [
    "# debugging workflow\n",
    "When building a new Sequential architecture, it's useful to incrementally stack layers with add() and frequently print model summaries. For instance, this enables you to monitor how a stack of Conv2D and MaxPooling2D layers is downsampling image feature maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "apparent-split",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 123, 32)      2432      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 121, 121, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 40, 40, 32)        0         \n",
      "=================================================================\n",
      "Total params: 11,680\n",
      "Trainable params: 11,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Input(shape=(250, 250, 3)))  # 250x250 RGB images\n",
    "model.add(layers.Conv2D(32, 5, strides=2, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "# Can you guess what the current output shape is at this point? Probably not.\n",
    "# Let's just print it:\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "classical-adrian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 123, 32)      2432      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 121, 121, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 40, 40, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 38, 38, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 36, 36, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "=================================================================\n",
      "Total params: 48,672\n",
      "Trainable params: 48,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The answer was: (40, 40, 32), so we can keep downsampling...\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "# And now?\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "altered-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 123, 32)      2432      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 121, 121, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 40, 40, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 38, 38, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 36, 36, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 49,002\n",
      "Trainable params: 49,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Now that we have 4x4 feature maps, time to apply global max pooling.\n",
    "model.add(layers.GlobalMaxPooling2D())\n",
    "\n",
    "# Finally, we add a classification layer.\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "# And now?\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-intellectual",
   "metadata": {},
   "source": [
    "# Functional API\n",
    "The Keras functional API is a way to create models that are more flexible than the tf.keras.Sequential API. The functional API can handle models with non-linear topology, shared layers, and even multiple inputs or outputs.\n",
    "\n",
    "The main idea is that a deep learning model is usually a directed acyclic graph (DAG) of layers. So the functional API is a way to build graphs of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-niger",
   "metadata": {},
   "source": [
    "* Consider the following model:\n",
    "><pre>\n",
    "(input: 784-dimensional vectors)\n",
    "       ↧\n",
    "[Dense (64 units, relu activation)]\n",
    "       ↧\n",
    "[Dense (64 units, relu activation)]\n",
    "       ↧\n",
    "[Dense (10 units, softmax activation)]\n",
    "       ↧\n",
    "(output: logits of a probability distribution over 10 classes)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-latin",
   "metadata": {},
   "source": [
    "This is a basic graph with three layers. To build this model using the functional API, start by creating an input node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "interim-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(784,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "beginning-enterprise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([None, 784]), tf.float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The inputs that is returned contains information about the shape and dtype of the input data that you feed to your model.\n",
    "# Here's the shape:\n",
    "inputs.shape, inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "indie-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If, for example, you have an image input with a shape of (32, 32, 3), you would use:\n",
    "img_inputs = tf.keras.Input(shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-occurrence",
   "metadata": {},
   "source": [
    "You create a new node in the graph of layers by calling a layer on this inputs object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "quantitative-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = layers.Dense(64, activation=\"relu\")\n",
    "x = dense(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-dover",
   "metadata": {},
   "source": [
    "The \"layer call\" action is like drawing an arrow from \"inputs\" to this layer you created. You're \"passing\" the inputs to the dense layer, and you get x as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "satisfied-thursday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add a few more layers to the graph of layers:\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(10)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-district",
   "metadata": {},
   "source": [
    "At this point, you can create a Model by specifying its inputs and outputs in the graph of layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "tight-acting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-credit",
   "metadata": {},
   "source": [
    "You can also plot the model as a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "convenient-sight",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'intermediate/model.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-88f24a791060>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"intermediate/model.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m   \u001b[0;31m# Save image to disk.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m   \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m   \u001b[0;31m# Return the image as a Jupyter Image object, to be displayed in-line.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;31m# Note that we cannot easily detect whether the code is running in a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pydotplus/graphviz.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, path, prog, format)\u001b[0m\n\u001b[1;32m   1886\u001b[0m             \u001b[0mprog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1888\u001b[0;31m         \u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w+b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1889\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pydotplus/graphviz.py\u001b[0m in \u001b[0;36mget_fobj\u001b[0;34m(fname, mode)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \"\"\"\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'intermediate/model.png'"
     ]
    }
   ],
   "source": [
    "utils.plot_model(model, \"intermediate/model.png\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-coast",
   "metadata": {},
   "source": [
    "This figure and the code are almost identical. In the code version, the connection arrows are replaced by the call operation.\n",
    "\n",
    "A \"graph of layers\" is an intuitive mental image for a deep learning model, and the functional API is a way to create models that closely mirrors this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-romantic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-baltimore",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
