https://parksuseong.blogspot.com/2019/04/312-3-standalone-pseudo-distributed.html

#########################################################################################
###                              Private Helm Repository                              ###
#########################################################################################
user:~$ helm package <project>
user:~$ mv project-0.1.0.tgz stable
user:~$ helm repo index stable --url https://nockchun.github.io/rsnet-helm/stable
user:~$ git add .
user:~$ git commit -m "add project chart"
user:~$ git push

user:~$ helm repo add rsnet-helm https://nockchun.github.io/rsnet-helm/stable
user:~$ helm search repo rsnet-helm
user:~$ helm install rsnet-helm/project




#########################################################################################
###                                      Hadoop                                       ###
#########################################################################################
* All Nodes -----------------------------------------------------------------------------
user:~$ sudo vi /etc/hosts
192.168.0.200 vmaster
192.168.0.201 vnode01
192.168.0.202 vnode02

user:~$ sudo apt install openjdk-11-jdk
user:~$ wget http://apache.mirror.cdnetworks.com/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz
user:~$ tar xfvz hadoop-3.2.1.tar.gz
user:~$ sudo mv hadoop-3.2.1 /opt/hadoop
user:~$ rm -rf hadoop-3.2.1.tar.gz
user:~$ sudo chown -R rsnet.rsnet /opt/hadoop/

user:~$ sudo vi /etc/bash.bashrc
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export HADOOP_HOME=/opt/hadoop

export HADOOP_INSTALL=$HADOOP_HOME
export HADOOP_MAPRED_HOME=${HADOOP_HOME}
export HADOOP_COMMON_HOME=${HADOOP_HOME}
export HADOOP_HDFS_HOME=${HADOOP_HOME}
export YARN_HOME=${HADOOP_HOME}
export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export HADOOP_COMMON_LIB_NATIVE_DIR=${HADOOP_HOME}/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_COMMON_LIB_NATIVE_DIR"

export PATH=$PATH:$HADOOP_HOME/bin:$JAVA_HOME/bin:$HADOOP_HOME/sbin

user:~$ vi $HADOOP_HOME/etc/hadoop/hadoop-env.sh
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export HADOOP_HOME=/opt/hadoop

user:~$ vi $HADOOP_HOME/etc/hadoop/core-site.xml
<configuration>
    <property>
        <name>fs.default.name</name>
        <value>hdfs://vmaster:9000</value>
    </property>
</configuration>

user:~$ vi $HADOOP_HOME/etc/hadoop/hdfs-site.xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///opt/hadoop/data/namenode</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:///opt/hadoop/data/datanode</value>
    </property>
</configuration>

user:~$ vi workers
vnode01
vnode02

user:~$ vi $HADOOP_HOME/etc/hadoop/yarn-site.xml
<configuration>
    <property>
        <name>yarn.acl.enable</name>
        <value>0</value>
    </property>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>vmaster</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
</configuration>


user:~$ vi $HADOOP_HOME/etc/hadoop/mapred-site.xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>yarn.app.mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>
    </property>
    <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>
    </property>
    <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>
    </property>
</configuration>

user:~$ ssh-keygen -t rsa -p ""
user:~$ ssh-copy-id rsnet@vmaster
user:~$ ssh-copy-id rsnet@vnode01
user:~$ ssh-copy-id rsnet@vnode02

user:~$ hdfs namenode -format
